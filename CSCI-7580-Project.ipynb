{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepspeed\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to data/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182040794/182040794 [01:01<00:00, 2960470.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64275384/64275384 [00:08<00:00, 7504093.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FashionMNIST\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Dataset: CIFAR10\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Dataset: CIFAR100\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Dataset: MNIST\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Dataset: SVHN\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "batch_size = 64\n",
    "datasets_list = [\n",
    "    (\n",
    "     \"FashionMNIST\",\n",
    "     datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor()),\n",
    "     datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "    ),\n",
    "    (\n",
    "     \"CIFAR10\",\n",
    "     datasets.CIFAR10(root=\"data\", train=True, download=True, transform=ToTensor()),\n",
    "     datasets.CIFAR10(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "    ),\n",
    "    (\n",
    "     \"CIFAR100\",\n",
    "     datasets.CIFAR100(root=\"data\", train=True, download=True, transform=ToTensor()),\n",
    "     datasets.CIFAR100(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "    ),\n",
    "    (\n",
    "     \"MNIST\",\n",
    "     datasets.MNIST(root=\"data\", train=True, download=True, transform=ToTensor()),\n",
    "     datasets.MNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "    ),\n",
    "    (\n",
    "     \"SVHN\",\n",
    "     datasets.SVHN(root=\"data\", split=\"train\", download=True, transform=ToTensor()),\n",
    "     datasets.SVHN(root=\"data\", split=\"test\", download=True, transform=ToTensor())\n",
    "    )\n",
    "]\n",
    "\n",
    "dataloaders_list = []\n",
    "for dataset in datasets_list:\n",
    "    dataloaders_list.append(\n",
    "        (\n",
    "            # Dataset Name\n",
    "            dataset[0],\n",
    "\n",
    "            # Training Dataloader\n",
    "            DataLoader(dataset[1], batch_size=batch_size),\n",
    "\n",
    "            # Testing Dataloader\n",
    "            DataLoader(dataset[2], batch_size=batch_size)\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataloader in dataloaders_list:\n",
    "    for X, y in dataloader[2]:\n",
    "        print(f\"Dataset: {dataloader[0]}\")\n",
    "        print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/andrew/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/home/andrew/.local/lib/python3.10/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "models_list = [\n",
    "    (\n",
    "        \"AlexNet\",\n",
    "        models.alexnet(pretrained=False)\n",
    "    ),\n",
    "    (\n",
    "        \"VGG16\",\n",
    "        models.vgg16(pretrained=False)\n",
    "    ),\n",
    "    (\n",
    "        \"Inception\",\n",
    "        models.inception_v3(pretrained=False)\n",
    "    ),\n",
    "    (\n",
    "        \"ResNet50\",\n",
    "        models.resnet50(pretrained=False)\n",
    "    )\n",
    "]\n",
    "\n",
    "loss_fn_list = [\n",
    "    nn.CrossEntropyLoss()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-20 16:03:16,988] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown\n",
      "[2023-11-20 16:03:16,994] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-11-20 16:03:16,995] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name SGD as basic optimizer\n",
      "[2023-11-20 16:03:16,996] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2023-11-20 16:03:16,997] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD\n",
      "[2023-11-20 16:03:16,998] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=SGD type=<class 'torch.optim.sgd.SGD'>\n",
      "[2023-11-20 16:03:16,999] [WARNING] [engine.py:1160:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****\n",
      "[2023-11-20 16:03:17,000] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-11-20 16:03:17,000] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 500,000,000\n",
      "[2023-11-20 16:03:17,001] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 500,000,000\n",
      "[2023-11-20 16:03:17,001] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: False\n",
      "[2023-11-20 16:03:17,002] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False\n",
      "[2023-11-20 16:03:17,110] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
      "[2023-11-20 16:03:17,112] [INFO] [utils.py:803:see_memory_usage] MA 0.03 GB         Max_MA 0.03 GB         CA 0.04 GB         Max_CA 0 GB \n",
      "[2023-11-20 16:03:17,113] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.04 GB, percent = 19.5%\n",
      "[2023-11-20 16:03:17,178] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
      "[2023-11-20 16:03:17,180] [INFO] [utils.py:803:see_memory_usage] MA 0.03 GB         Max_MA 0.03 GB         CA 0.04 GB         Max_CA 0 GB \n",
      "[2023-11-20 16:03:17,181] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.04 GB, percent = 19.5%\n",
      "[2023-11-20 16:03:17,181] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized\n",
      "[2023-11-20 16:03:17,251] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-11-20 16:03:17,252] [INFO] [utils.py:803:see_memory_usage] MA 0.03 GB         Max_MA 0.03 GB         CA 0.04 GB         Max_CA 0 GB \n",
      "[2023-11-20 16:03:17,254] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.04 GB, percent = 19.5%\n",
      "[2023-11-20 16:03:17,255] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD\n",
      "[2023-11-20 16:03:17,255] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-11-20 16:03:17,256] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-11-20 16:03:17,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:17,257] [INFO] [config.py:974:print] DeepSpeedEngine configuration:\n",
      "[2023-11-20 16:03:17,257] [INFO] [config.py:978:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-11-20 16:03:17,258] [INFO] [config.py:978:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-11-20 16:03:17,258] [INFO] [config.py:978:print]   amp_enabled .................. False\n",
      "[2023-11-20 16:03:17,259] [INFO] [config.py:978:print]   amp_params ................... False\n",
      "[2023-11-20 16:03:17,259] [INFO] [config.py:978:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-11-20 16:03:17,260] [INFO] [config.py:978:print]   bfloat16_enabled ............. False\n",
      "[2023-11-20 16:03:17,260] [INFO] [config.py:978:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-11-20 16:03:17,263] [INFO] [config.py:978:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-11-20 16:03:17,263] [INFO] [config.py:978:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-11-20 16:03:17,264] [INFO] [config.py:978:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7efd983ac700>\n",
      "[2023-11-20 16:03:17,264] [INFO] [config.py:978:print]   communication_data_type ...... None\n",
      "[2023-11-20 16:03:17,265] [INFO] [config.py:978:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-11-20 16:03:17,265] [INFO] [config.py:978:print]   curriculum_enabled_legacy .... False\n",
      "[2023-11-20 16:03:17,266] [INFO] [config.py:978:print]   curriculum_params_legacy ..... False\n",
      "[2023-11-20 16:03:17,266] [INFO] [config.py:978:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-11-20 16:03:17,267] [INFO] [config.py:978:print]   data_efficiency_enabled ...... False\n",
      "[2023-11-20 16:03:17,267] [INFO] [config.py:978:print]   dataloader_drop_last ......... False\n",
      "[2023-11-20 16:03:17,268] [INFO] [config.py:978:print]   disable_allgather ............ False\n",
      "[2023-11-20 16:03:17,268] [INFO] [config.py:978:print]   dump_state ................... False\n",
      "[2023-11-20 16:03:17,269] [INFO] [config.py:978:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-11-20 16:03:17,269] [INFO] [config.py:978:print]   eigenvalue_enabled ........... False\n",
      "[2023-11-20 16:03:17,270] [INFO] [config.py:978:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-11-20 16:03:17,271] [INFO] [config.py:978:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-11-20 16:03:17,271] [INFO] [config.py:978:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-11-20 16:03:17,272] [INFO] [config.py:978:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-11-20 16:03:17,272] [INFO] [config.py:978:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-11-20 16:03:17,274] [INFO] [config.py:978:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-11-20 16:03:17,274] [INFO] [config.py:978:print]   eigenvalue_verbose ........... False\n",
      "[2023-11-20 16:03:17,275] [INFO] [config.py:978:print]   elasticity_enabled ........... False\n",
      "[2023-11-20 16:03:17,275] [INFO] [config.py:978:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-11-20 16:03:17,276] [INFO] [config.py:978:print]   fp16_auto_cast ............... False\n",
      "[2023-11-20 16:03:17,277] [INFO] [config.py:978:print]   fp16_enabled ................. True\n",
      "[2023-11-20 16:03:17,277] [INFO] [config.py:978:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-11-20 16:03:17,278] [INFO] [config.py:978:print]   global_rank .................. 0\n",
      "[2023-11-20 16:03:17,278] [INFO] [config.py:978:print]   grad_accum_dtype ............. None\n",
      "[2023-11-20 16:03:17,279] [INFO] [config.py:978:print]   gradient_accumulation_steps .. 1\n",
      "[2023-11-20 16:03:17,279] [INFO] [config.py:978:print]   gradient_clipping ............ 1.0\n",
      "[2023-11-20 16:03:17,280] [INFO] [config.py:978:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-11-20 16:03:17,280] [INFO] [config.py:978:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-11-20 16:03:17,281] [INFO] [config.py:978:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-11-20 16:03:17,281] [INFO] [config.py:978:print]   load_universal_checkpoint .... False\n",
      "[2023-11-20 16:03:17,282] [INFO] [config.py:978:print]   loss_scale ................... 0\n",
      "[2023-11-20 16:03:17,282] [INFO] [config.py:978:print]   memory_breakdown ............. False\n",
      "[2023-11-20 16:03:17,283] [INFO] [config.py:978:print]   mics_hierarchial_params_gather  False\n",
      "[2023-11-20 16:03:17,283] [INFO] [config.py:978:print]   mics_shard_size .............. -1\n",
      "[2023-11-20 16:03:17,284] [INFO] [config.py:978:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-11-20 16:03:17,284] [INFO] [config.py:978:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-11-20 16:03:17,285] [INFO] [config.py:978:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-11-20 16:03:17,285] [INFO] [config.py:978:print]   optimizer_name ............... SGD\n",
      "[2023-11-20 16:03:17,286] [INFO] [config.py:978:print]   optimizer_params ............. {'lr': 0.001}\n",
      "[2023-11-20 16:03:17,286] [INFO] [config.py:978:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2023-11-20 16:03:17,287] [INFO] [config.py:978:print]   pld_enabled .................. False\n",
      "[2023-11-20 16:03:17,289] [INFO] [config.py:978:print]   pld_params ................... False\n",
      "[2023-11-20 16:03:17,289] [INFO] [config.py:978:print]   prescale_gradients ........... False\n",
      "[2023-11-20 16:03:17,290] [INFO] [config.py:978:print]   scheduler_name ............... None\n",
      "[2023-11-20 16:03:17,290] [INFO] [config.py:978:print]   scheduler_params ............. None\n",
      "[2023-11-20 16:03:17,291] [INFO] [config.py:978:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2023-11-20 16:03:17,291] [INFO] [config.py:978:print]   sparse_attention ............. None\n",
      "[2023-11-20 16:03:17,292] [INFO] [config.py:978:print]   sparse_gradients_enabled ..... False\n",
      "[2023-11-20 16:03:17,293] [INFO] [config.py:978:print]   steps_per_print .............. 10\n",
      "[2023-11-20 16:03:17,293] [INFO] [config.py:978:print]   train_batch_size ............. 64\n",
      "[2023-11-20 16:03:17,294] [INFO] [config.py:978:print]   train_micro_batch_size_per_gpu  64\n",
      "[2023-11-20 16:03:17,294] [INFO] [config.py:978:print]   use_node_local_storage ....... False\n",
      "[2023-11-20 16:03:17,295] [INFO] [config.py:978:print]   wall_clock_breakdown ......... False\n",
      "[2023-11-20 16:03:17,295] [INFO] [config.py:978:print]   weight_quantization_config ... None\n",
      "[2023-11-20 16:03:17,296] [INFO] [config.py:978:print]   world_size ................... 1\n",
      "[2023-11-20 16:03:17,296] [INFO] [config.py:978:print]   zero_allow_untested_optimizer  True\n",
      "[2023-11-20 16:03:17,297] [INFO] [config.py:978:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2023-11-20 16:03:17,297] [INFO] [config.py:978:print]   zero_enabled ................. True\n",
      "[2023-11-20 16:03:17,298] [INFO] [config.py:978:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-11-20 16:03:17,298] [INFO] [config.py:978:print]   zero_optimization_stage ...... 2\n",
      "[2023-11-20 16:03:17,299] [INFO] [config.py:964:print_user_config]   json = {\n",
      "    \"train_micro_batch_size_per_gpu\": 64, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"SGD\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.001\n",
      "        }\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[2023-11-20 16:03:17,351] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "loss: 2.308594  [   64/60000]\n",
      "[2023-11-20 16:03:17,364] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "[2023-11-20 16:03:17,377] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "[2023-11-20 16:03:17,390] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "[2023-11-20 16:03:17,405] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "[2023-11-20 16:03:17,419] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "[2023-11-20 16:03:17,431] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "[2023-11-20 16:03:17,444] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "[2023-11-20 16:03:17,457] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "[2023-11-20 16:03:17,472] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "[2023-11-20 16:03:17,473] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:17,473] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=8806.576370719704, CurrSamplesPerSec=7236.432295457609, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:17,487] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "[2023-11-20 16:03:17,502] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576\n",
      "[2023-11-20 16:03:17,515] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288\n",
      "[2023-11-20 16:03:17,528] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144\n",
      "[2023-11-20 16:03:17,540] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072\n",
      "[2023-11-20 16:03:17,554] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536\n",
      "[2023-11-20 16:03:17,569] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2023-11-20 16:03:17,609] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:17,610] [INFO] [timer.py:260:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=8552.42555405891, CurrSamplesPerSec=8218.334384471726, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:17,756] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:17,757] [INFO] [timer.py:260:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=8042.846392636212, CurrSamplesPerSec=6129.22312539958, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:17,894] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:17,896] [INFO] [timer.py:260:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=7981.96745566529, CurrSamplesPerSec=7503.227191413238, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:18,041] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:18,042] [INFO] [timer.py:260:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=7854.8370485339365, CurrSamplesPerSec=6994.331691810626, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:18,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:18,184] [INFO] [timer.py:260:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=7831.724298066422, CurrSamplesPerSec=7009.856792186765, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:18,327] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:18,328] [INFO] [timer.py:260:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=7763.384407573182, CurrSamplesPerSec=6780.042836936755, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:18,476] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:18,477] [INFO] [timer.py:260:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=7684.503089514442, CurrSamplesPerSec=8058.220941402497, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:18,618] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:18,619] [INFO] [timer.py:260:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=7666.060060699367, CurrSamplesPerSec=7651.221525481701, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:18,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:18,762] [INFO] [timer.py:260:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=7669.054554539526, CurrSamplesPerSec=7561.136161343023, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.296875  [ 6464/60000]\n",
      "[2023-11-20 16:03:18,903] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:18,904] [INFO] [timer.py:260:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=7672.64133488104, CurrSamplesPerSec=6987.595168679717, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:19,043] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:19,044] [INFO] [timer.py:260:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=7677.023548726878, CurrSamplesPerSec=7299.003616390679, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:19,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:19,185] [INFO] [timer.py:260:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=7691.799679476058, CurrSamplesPerSec=7730.545328879161, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:19,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:19,335] [INFO] [timer.py:260:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=7653.320754405132, CurrSamplesPerSec=7296.226142263054, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:19,480] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:19,481] [INFO] [timer.py:260:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=7633.499226340657, CurrSamplesPerSec=7073.584442277794, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:19,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:19,630] [INFO] [timer.py:260:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=7605.4074708463695, CurrSamplesPerSec=7223.19123859753, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:19,773] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:19,774] [INFO] [timer.py:260:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=7598.02092064167, CurrSamplesPerSec=7199.5562826874075, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:19,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:19,915] [INFO] [timer.py:260:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=7595.23647938065, CurrSamplesPerSec=6678.828025477707, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:20,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:20,056] [INFO] [timer.py:260:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=7600.293573980318, CurrSamplesPerSec=7549.440503979526, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:20,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:20,197] [INFO] [timer.py:260:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=7606.699118156092, CurrSamplesPerSec=6983.232466181062, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.271484  [12864/60000]\n",
      "[2023-11-20 16:03:20,339] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:20,341] [INFO] [timer.py:260:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=7610.310798818161, CurrSamplesPerSec=7224.552050812789, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:20,483] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:20,484] [INFO] [timer.py:260:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=7609.098605423832, CurrSamplesPerSec=7935.772955714539, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:20,622] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:20,623] [INFO] [timer.py:260:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=7625.385885869049, CurrSamplesPerSec=6387.062339392785, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:20,764] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:20,765] [INFO] [timer.py:260:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=7627.695315497867, CurrSamplesPerSec=8078.592030817383, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:20,901] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:20,903] [INFO] [timer.py:260:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=7642.575700275811, CurrSamplesPerSec=6752.923347840306, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:21,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:21,053] [INFO] [timer.py:260:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=7618.154741616425, CurrSamplesPerSec=5478.162813003816, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:21,189] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:21,190] [INFO] [timer.py:260:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=7633.579677601657, CurrSamplesPerSec=6933.450149808865, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:21,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:21,327] [INFO] [timer.py:260:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=7645.295518287635, CurrSamplesPerSec=7292.261986906088, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:21,471] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:21,472] [INFO] [timer.py:260:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=7641.125811783139, CurrSamplesPerSec=6915.944143865616, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:21,623] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:21,624] [INFO] [timer.py:260:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=7623.252186828834, CurrSamplesPerSec=5698.661628277253, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.257812  [19264/60000]\n",
      "[2023-11-20 16:03:21,771] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:21,772] [INFO] [timer.py:260:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=7622.017552611141, CurrSamplesPerSec=7120.3038726790455, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:21,917] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:21,918] [INFO] [timer.py:260:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=7620.09831998486, CurrSamplesPerSec=7701.711596947266, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:22,058] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:22,059] [INFO] [timer.py:260:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=7618.536941456985, CurrSamplesPerSec=7152.747368701537, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:22,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:22,206] [INFO] [timer.py:260:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=7612.585943824161, CurrSamplesPerSec=7363.878309055496, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:22,356] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:22,357] [INFO] [timer.py:260:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=7602.494626687235, CurrSamplesPerSec=6512.894409937888, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:22,505] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:22,506] [INFO] [timer.py:260:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=7589.650236622023, CurrSamplesPerSec=5427.104767296106, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:22,663] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:22,664] [INFO] [timer.py:260:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=7578.8431098097835, CurrSamplesPerSec=6100.112623565504, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:22,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:22,817] [INFO] [timer.py:260:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=7569.769352582959, CurrSamplesPerSec=5685.866768337887, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:22,965] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:22,967] [INFO] [timer.py:260:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=7560.556554987024, CurrSamplesPerSec=7103.910233678249, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:23,125] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:23,127] [INFO] [timer.py:260:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=7540.816755659108, CurrSamplesPerSec=6486.455055093756, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.257812  [25664/60000]\n",
      "[2023-11-20 16:03:23,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:23,297] [INFO] [timer.py:260:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=7506.337903023455, CurrSamplesPerSec=6218.533972710636, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:23,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:23,455] [INFO] [timer.py:260:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=7493.302843148477, CurrSamplesPerSec=7186.257321839696, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:23,602] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:23,603] [INFO] [timer.py:260:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=7488.914153232369, CurrSamplesPerSec=6575.43249069175, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:23,750] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:23,751] [INFO] [timer.py:260:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=7489.1077089354385, CurrSamplesPerSec=7178.570251912071, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:23,895] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:23,896] [INFO] [timer.py:260:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=7487.582248255526, CurrSamplesPerSec=7998.911052176763, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:24,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:24,040] [INFO] [timer.py:260:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=7488.217311319135, CurrSamplesPerSec=7503.4369252271135, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:24,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:24,184] [INFO] [timer.py:260:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=7487.974559870368, CurrSamplesPerSec=7801.995465907109, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:24,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:24,327] [INFO] [timer.py:260:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=7488.5731555575485, CurrSamplesPerSec=7177.226705168311, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:24,465] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:24,466] [INFO] [timer.py:260:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=7496.008413607141, CurrSamplesPerSec=7679.677747897236, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:24,602] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:24,602] [INFO] [timer.py:260:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=7505.6592233590245, CurrSamplesPerSec=6753.60293858656, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.208984  [32064/60000]\n",
      "[2023-11-20 16:03:24,742] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:24,743] [INFO] [timer.py:260:stop] epoch=0/micro_step=510/global_step=510, RunningAvgSamplesPerSec=7513.577983699641, CurrSamplesPerSec=7922.890587644993, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:24,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:24,891] [INFO] [timer.py:260:stop] epoch=0/micro_step=520/global_step=520, RunningAvgSamplesPerSec=7510.640983381204, CurrSamplesPerSec=6368.877669165797, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:25,042] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:25,043] [INFO] [timer.py:260:stop] epoch=0/micro_step=530/global_step=530, RunningAvgSamplesPerSec=7507.2491318675675, CurrSamplesPerSec=7296.424463169339, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:25,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:25,191] [INFO] [timer.py:260:stop] epoch=0/micro_step=540/global_step=540, RunningAvgSamplesPerSec=7504.222946568692, CurrSamplesPerSec=6253.592451951077, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:25,331] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:25,332] [INFO] [timer.py:260:stop] epoch=0/micro_step=550/global_step=550, RunningAvgSamplesPerSec=7506.145764499525, CurrSamplesPerSec=7633.8145830963485, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:25,477] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:25,478] [INFO] [timer.py:260:stop] epoch=0/micro_step=560/global_step=560, RunningAvgSamplesPerSec=7504.37974459044, CurrSamplesPerSec=6522.23087202663, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:25,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:25,625] [INFO] [timer.py:260:stop] epoch=0/micro_step=570/global_step=570, RunningAvgSamplesPerSec=7501.381079751521, CurrSamplesPerSec=5761.901262127586, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:25,764] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:25,765] [INFO] [timer.py:260:stop] epoch=0/micro_step=580/global_step=580, RunningAvgSamplesPerSec=7504.092328240701, CurrSamplesPerSec=5204.0528866658915, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:25,910] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:25,911] [INFO] [timer.py:260:stop] epoch=0/micro_step=590/global_step=590, RunningAvgSamplesPerSec=7501.722659439718, CurrSamplesPerSec=7229.026903293567, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:26,061] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:26,061] [INFO] [timer.py:260:stop] epoch=0/micro_step=600/global_step=600, RunningAvgSamplesPerSec=7492.656454647077, CurrSamplesPerSec=7389.013074953894, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.220703  [38464/60000]\n",
      "[2023-11-20 16:03:26,208] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:26,209] [INFO] [timer.py:260:stop] epoch=0/micro_step=610/global_step=610, RunningAvgSamplesPerSec=7489.283820504531, CurrSamplesPerSec=6855.188109709383, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:26,349] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:26,350] [INFO] [timer.py:260:stop] epoch=0/micro_step=620/global_step=620, RunningAvgSamplesPerSec=7493.031927558388, CurrSamplesPerSec=6978.149526879484, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:26,488] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:26,489] [INFO] [timer.py:260:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=7496.939624269512, CurrSamplesPerSec=6928.975916987171, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:26,626] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:26,627] [INFO] [timer.py:260:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=7501.460041571646, CurrSamplesPerSec=6533.0247998247705, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:26,762] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:26,763] [INFO] [timer.py:260:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=7512.642441579986, CurrSamplesPerSec=7936.711489563007, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:26,901] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:26,902] [INFO] [timer.py:260:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=7517.551685428072, CurrSamplesPerSec=7412.477384436958, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:27,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:27,050] [INFO] [timer.py:260:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=7513.814533217983, CurrSamplesPerSec=7610.008958439644, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:27,198] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:27,199] [INFO] [timer.py:260:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=7511.189828122623, CurrSamplesPerSec=7721.206235977679, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:27,341] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:27,342] [INFO] [timer.py:260:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=7511.531906123948, CurrSamplesPerSec=7064.462761197958, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:27,483] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:27,484] [INFO] [timer.py:260:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=7514.4807152218045, CurrSamplesPerSec=7170.133447299535, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.181641  [44864/60000]\n",
      "[2023-11-20 16:03:27,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:27,630] [INFO] [timer.py:260:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=7511.232044815961, CurrSamplesPerSec=7181.258855002675, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:27,770] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:27,771] [INFO] [timer.py:260:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=7515.546556604152, CurrSamplesPerSec=7459.648631374183, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:27,921] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:27,922] [INFO] [timer.py:260:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=7510.019243335084, CurrSamplesPerSec=6593.359762238106, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:28,062] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:28,064] [INFO] [timer.py:260:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=7510.586817150333, CurrSamplesPerSec=7438.563914983235, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:28,203] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:28,204] [INFO] [timer.py:260:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=7513.812617175449, CurrSamplesPerSec=6951.765059304916, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:28,345] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:28,346] [INFO] [timer.py:260:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=7516.0382826748755, CurrSamplesPerSec=7491.082658927276, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:28,482] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:28,483] [INFO] [timer.py:260:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=7522.659198830695, CurrSamplesPerSec=7291.271621034333, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:28,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:28,625] [INFO] [timer.py:260:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=7524.454774086519, CurrSamplesPerSec=6620.026535796197, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:28,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:28,779] [INFO] [timer.py:260:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=7518.753571500677, CurrSamplesPerSec=7390.64056606371, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:28,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:28,910] [INFO] [timer.py:260:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=7531.769524467058, CurrSamplesPerSec=7448.264594894562, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.185547  [51264/60000]\n",
      "[2023-11-20 16:03:29,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,046] [INFO] [timer.py:260:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=7539.699797682587, CurrSamplesPerSec=8065.969230769231, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:29,182] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,183] [INFO] [timer.py:260:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=7549.136831983832, CurrSamplesPerSec=7904.6925998998795, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:29,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,323] [INFO] [timer.py:260:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=7551.7295290013635, CurrSamplesPerSec=8164.343684418626, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:29,456] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,458] [INFO] [timer.py:260:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=7559.011809689943, CurrSamplesPerSec=7627.957602796169, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:29,584] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,585] [INFO] [timer.py:260:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=7571.418767921699, CurrSamplesPerSec=8641.646202878022, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:29,715] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,716] [INFO] [timer.py:260:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=7582.913997501879, CurrSamplesPerSec=8186.254033118844, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:29,845] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,846] [INFO] [timer.py:260:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=7593.59724416679, CurrSamplesPerSec=8536.122873406048, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:29,977] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:29,978] [INFO] [timer.py:260:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=7602.217136623507, CurrSamplesPerSec=8229.924763160316, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:30,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:30,112] [INFO] [timer.py:260:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=7609.026108361898, CurrSamplesPerSec=7682.535016170115, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:30,238] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:30,239] [INFO] [timer.py:260:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=7621.974399112132, CurrSamplesPerSec=8726.48665518026, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.150391  [57664/60000]\n",
      "[2023-11-20 16:03:30,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:30,381] [INFO] [timer.py:260:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=7623.261747910611, CurrSamplesPerSec=7315.114889906256, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:30,522] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:30,523] [INFO] [timer.py:260:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=7626.934865258605, CurrSamplesPerSec=7263.846732512515, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:30,654] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:30,655] [INFO] [timer.py:260:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=7636.154885120991, CurrSamplesPerSec=8376.82808550476, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "Test Error: \n",
      " Accuracy: 42.1%, Avg loss: 2.148201 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.162109  [   64/60000]\n",
      "[2023-11-20 16:03:31,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:31,727] [INFO] [timer.py:260:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=7646.499853427574, CurrSamplesPerSec=8385.72540689138, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:31,854] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:31,855] [INFO] [timer.py:260:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=7656.47222925007, CurrSamplesPerSec=8403.31379914851, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:31,987] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:31,988] [INFO] [timer.py:260:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=7663.104756991643, CurrSamplesPerSec=7949.638878194687, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:32,124] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:32,125] [INFO] [timer.py:260:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=7666.974110437902, CurrSamplesPerSec=5909.160983556035, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:32,263] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:32,264] [INFO] [timer.py:260:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=7668.501950528047, CurrSamplesPerSec=6703.010362823682, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:32,407] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:32,408] [INFO] [timer.py:260:stop] epoch=0/micro_step=990/global_step=990, RunningAvgSamplesPerSec=7668.8020530467575, CurrSamplesPerSec=6454.171719843235, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:32,549] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:32,550] [INFO] [timer.py:260:stop] epoch=0/micro_step=1000/global_step=1000, RunningAvgSamplesPerSec=7668.96092868487, CurrSamplesPerSec=6579.622922692289, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:32,685] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=17, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:32,687] [INFO] [timer.py:260:stop] epoch=0/micro_step=1010/global_step=1010, RunningAvgSamplesPerSec=7672.463805804672, CurrSamplesPerSec=7514.779989362, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:32,794] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2023-11-20 16:03:32,822] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:32,823] [INFO] [timer.py:260:stop] epoch=0/micro_step=1020/global_step=1020, RunningAvgSamplesPerSec=7676.338255954187, CurrSamplesPerSec=7082.542835281391, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:32,960] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:32,961] [INFO] [timer.py:260:stop] epoch=0/micro_step=1030/global_step=1030, RunningAvgSamplesPerSec=7677.788039226794, CurrSamplesPerSec=7651.657716207742, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.154297  [ 6464/60000]\n",
      "[2023-11-20 16:03:33,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:33,097] [INFO] [timer.py:260:stop] epoch=0/micro_step=1040/global_step=1040, RunningAvgSamplesPerSec=7681.570921650106, CurrSamplesPerSec=8343.500947999875, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:33,231] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:33,232] [INFO] [timer.py:260:stop] epoch=0/micro_step=1050/global_step=1050, RunningAvgSamplesPerSec=7686.237692745853, CurrSamplesPerSec=8550.533732560361, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:33,367] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:33,368] [INFO] [timer.py:260:stop] epoch=0/micro_step=1060/global_step=1060, RunningAvgSamplesPerSec=7690.457725957468, CurrSamplesPerSec=7706.797278286584, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:33,504] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:33,505] [INFO] [timer.py:260:stop] epoch=0/micro_step=1070/global_step=1070, RunningAvgSamplesPerSec=7692.241999166244, CurrSamplesPerSec=7410.021973168443, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:33,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:33,648] [INFO] [timer.py:260:stop] epoch=0/micro_step=1080/global_step=1080, RunningAvgSamplesPerSec=7692.28331893977, CurrSamplesPerSec=7660.173386981708, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:33,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:33,787] [INFO] [timer.py:260:stop] epoch=0/micro_step=1090/global_step=1090, RunningAvgSamplesPerSec=7692.97510147516, CurrSamplesPerSec=7494.219715793294, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:33,921] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:33,922] [INFO] [timer.py:260:stop] epoch=0/micro_step=1100/global_step=1100, RunningAvgSamplesPerSec=7696.104677129279, CurrSamplesPerSec=7049.250420168068, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:34,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:34,056] [INFO] [timer.py:260:stop] epoch=0/micro_step=1110/global_step=1110, RunningAvgSamplesPerSec=7699.727958922011, CurrSamplesPerSec=7925.229724543119, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:34,188] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:34,190] [INFO] [timer.py:260:stop] epoch=0/micro_step=1120/global_step=1120, RunningAvgSamplesPerSec=7704.634934489991, CurrSamplesPerSec=7179.530236165717, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:34,332] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:34,333] [INFO] [timer.py:260:stop] epoch=0/micro_step=1130/global_step=1130, RunningAvgSamplesPerSec=7704.051501536598, CurrSamplesPerSec=7896.3216943668185, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.093750  [12864/60000]\n",
      "[2023-11-20 16:03:34,472] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:34,473] [INFO] [timer.py:260:stop] epoch=0/micro_step=1140/global_step=1140, RunningAvgSamplesPerSec=7704.974334740012, CurrSamplesPerSec=6474.8771286603305, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:34,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:34,622] [INFO] [timer.py:260:stop] epoch=0/micro_step=1150/global_step=1150, RunningAvgSamplesPerSec=7701.017372776323, CurrSamplesPerSec=7215.618945217999, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:34,767] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:34,768] [INFO] [timer.py:260:stop] epoch=0/micro_step=1160/global_step=1160, RunningAvgSamplesPerSec=7697.9685557086295, CurrSamplesPerSec=7386.9797187594595, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:34,908] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:34,909] [INFO] [timer.py:260:stop] epoch=0/micro_step=1170/global_step=1170, RunningAvgSamplesPerSec=7698.643635375652, CurrSamplesPerSec=7106.355059035315, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:35,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:35,046] [INFO] [timer.py:260:stop] epoch=0/micro_step=1180/global_step=1180, RunningAvgSamplesPerSec=7702.472126268556, CurrSamplesPerSec=7866.932067287967, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:35,181] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:35,182] [INFO] [timer.py:260:stop] epoch=0/micro_step=1190/global_step=1190, RunningAvgSamplesPerSec=7704.927057620149, CurrSamplesPerSec=7556.240844475721, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:35,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:35,318] [INFO] [timer.py:260:stop] epoch=0/micro_step=1200/global_step=1200, RunningAvgSamplesPerSec=7707.883982262929, CurrSamplesPerSec=7897.018592610026, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:35,455] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:35,456] [INFO] [timer.py:260:stop] epoch=0/micro_step=1210/global_step=1210, RunningAvgSamplesPerSec=7708.7754118733865, CurrSamplesPerSec=7687.815562619927, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:35,594] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:35,595] [INFO] [timer.py:260:stop] epoch=0/micro_step=1220/global_step=1220, RunningAvgSamplesPerSec=7710.097283591945, CurrSamplesPerSec=8544.54596384008, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:35,731] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:35,732] [INFO] [timer.py:260:stop] epoch=0/micro_step=1230/global_step=1230, RunningAvgSamplesPerSec=7712.303043664403, CurrSamplesPerSec=7699.502524093621, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.107422  [19264/60000]\n",
      "[2023-11-20 16:03:35,869] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:35,870] [INFO] [timer.py:260:stop] epoch=0/micro_step=1240/global_step=1240, RunningAvgSamplesPerSec=7713.415097309703, CurrSamplesPerSec=7253.640014051396, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,004] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,005] [INFO] [timer.py:260:stop] epoch=0/micro_step=1250/global_step=1250, RunningAvgSamplesPerSec=7716.296136937211, CurrSamplesPerSec=6898.349035026855, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,140] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,142] [INFO] [timer.py:260:stop] epoch=0/micro_step=1260/global_step=1260, RunningAvgSamplesPerSec=7717.727970248385, CurrSamplesPerSec=7085.346988333421, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,280] [INFO] [timer.py:260:stop] epoch=0/micro_step=1270/global_step=1270, RunningAvgSamplesPerSec=7717.824162318208, CurrSamplesPerSec=6984.140913230129, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,414] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,415] [INFO] [timer.py:260:stop] epoch=0/micro_step=1280/global_step=1280, RunningAvgSamplesPerSec=7720.736884967516, CurrSamplesPerSec=7015.902773058729, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,547] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,548] [INFO] [timer.py:260:stop] epoch=0/micro_step=1290/global_step=1290, RunningAvgSamplesPerSec=7724.715070029073, CurrSamplesPerSec=7750.633943523705, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,691] [INFO] [timer.py:260:stop] epoch=0/micro_step=1300/global_step=1300, RunningAvgSamplesPerSec=7722.886483488839, CurrSamplesPerSec=6402.295745086815, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,843] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,844] [INFO] [timer.py:260:stop] epoch=0/micro_step=1310/global_step=1310, RunningAvgSamplesPerSec=7719.566372995903, CurrSamplesPerSec=7347.5517600043795, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:36,995] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:36,996] [INFO] [timer.py:260:stop] epoch=0/micro_step=1320/global_step=1320, RunningAvgSamplesPerSec=7716.579311729882, CurrSamplesPerSec=6532.865806765636, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:37,140] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:37,142] [INFO] [timer.py:260:stop] epoch=0/micro_step=1330/global_step=1330, RunningAvgSamplesPerSec=7716.5062271836305, CurrSamplesPerSec=5901.366456350166, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.062500  [25664/60000]\n",
      "[2023-11-20 16:03:37,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:37,282] [INFO] [timer.py:260:stop] epoch=0/micro_step=1340/global_step=1340, RunningAvgSamplesPerSec=7717.532532582153, CurrSamplesPerSec=7668.708033367615, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:37,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:37,424] [INFO] [timer.py:260:stop] epoch=0/micro_step=1350/global_step=1350, RunningAvgSamplesPerSec=7718.595081929937, CurrSamplesPerSec=7749.962641106332, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:37,570] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:37,572] [INFO] [timer.py:260:stop] epoch=0/micro_step=1360/global_step=1360, RunningAvgSamplesPerSec=7715.224563604027, CurrSamplesPerSec=5878.234485174966, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:37,712] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:37,713] [INFO] [timer.py:260:stop] epoch=0/micro_step=1370/global_step=1370, RunningAvgSamplesPerSec=7715.30715922758, CurrSamplesPerSec=6219.110256469661, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:37,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:37,858] [INFO] [timer.py:260:stop] epoch=0/micro_step=1380/global_step=1380, RunningAvgSamplesPerSec=7714.240199117392, CurrSamplesPerSec=7235.262014500957, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:38,004] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,005] [INFO] [timer.py:260:stop] epoch=0/micro_step=1390/global_step=1390, RunningAvgSamplesPerSec=7715.2685985325425, CurrSamplesPerSec=7259.525002028287, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:38,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,156] [INFO] [timer.py:260:stop] epoch=0/micro_step=1400/global_step=1400, RunningAvgSamplesPerSec=7712.399861524323, CurrSamplesPerSec=7376.221587162014, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:38,289] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,290] [INFO] [timer.py:260:stop] epoch=0/micro_step=1410/global_step=1410, RunningAvgSamplesPerSec=7716.307418836112, CurrSamplesPerSec=8134.407757575757, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:38,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,426] [INFO] [timer.py:260:stop] epoch=0/micro_step=1420/global_step=1420, RunningAvgSamplesPerSec=7719.425065843719, CurrSamplesPerSec=6980.871609497309, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:38,561] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,562] [INFO] [timer.py:260:stop] epoch=0/micro_step=1430/global_step=1430, RunningAvgSamplesPerSec=7721.817967094943, CurrSamplesPerSec=6957.530869317298, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.989258  [32064/60000]\n",
      "[2023-11-20 16:03:38,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,708] [INFO] [timer.py:260:stop] epoch=0/micro_step=1440/global_step=1440, RunningAvgSamplesPerSec=7719.93444324662, CurrSamplesPerSec=6813.601441734142, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:38,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,843] [INFO] [timer.py:260:stop] epoch=0/micro_step=1450/global_step=1450, RunningAvgSamplesPerSec=7723.759896626146, CurrSamplesPerSec=7264.043297072036, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:38,978] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:38,979] [INFO] [timer.py:260:stop] epoch=0/micro_step=1460/global_step=1460, RunningAvgSamplesPerSec=7725.390144318228, CurrSamplesPerSec=6845.922215704777, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:39,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:39,114] [INFO] [timer.py:260:stop] epoch=0/micro_step=1470/global_step=1470, RunningAvgSamplesPerSec=7728.019292943251, CurrSamplesPerSec=6993.602792903108, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:39,246] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:39,247] [INFO] [timer.py:260:stop] epoch=0/micro_step=1480/global_step=1480, RunningAvgSamplesPerSec=7731.802675330962, CurrSamplesPerSec=7050.731666316453, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:39,386] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:39,387] [INFO] [timer.py:260:stop] epoch=0/micro_step=1490/global_step=1490, RunningAvgSamplesPerSec=7732.748301022298, CurrSamplesPerSec=7294.838197728137, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:39,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:39,529] [INFO] [timer.py:260:stop] epoch=0/micro_step=1500/global_step=1500, RunningAvgSamplesPerSec=7732.677530833353, CurrSamplesPerSec=7845.319616553659, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:39,664] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:39,665] [INFO] [timer.py:260:stop] epoch=0/micro_step=1510/global_step=1510, RunningAvgSamplesPerSec=7736.00726954156, CurrSamplesPerSec=8025.936016265025, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:39,798] [INFO] [timer.py:260:stop] epoch=0/micro_step=1520/global_step=1520, RunningAvgSamplesPerSec=7739.440592576902, CurrSamplesPerSec=7399.808578674606, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:39,935] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:39,936] [INFO] [timer.py:260:stop] epoch=0/micro_step=1530/global_step=1530, RunningAvgSamplesPerSec=7740.521677796337, CurrSamplesPerSec=7099.588891827559, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 2.025391  [38464/60000]\n",
      "[2023-11-20 16:03:40,080] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:40,081] [INFO] [timer.py:260:stop] epoch=0/micro_step=1540/global_step=1540, RunningAvgSamplesPerSec=7739.491344417449, CurrSamplesPerSec=6784.841168739258, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:40,217] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:40,218] [INFO] [timer.py:260:stop] epoch=0/micro_step=1550/global_step=1550, RunningAvgSamplesPerSec=7740.228398848873, CurrSamplesPerSec=6704.349659082394, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:40,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:40,363] [INFO] [timer.py:260:stop] epoch=0/micro_step=1560/global_step=1560, RunningAvgSamplesPerSec=7739.817087473969, CurrSamplesPerSec=7502.807758958019, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:40,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:40,512] [INFO] [timer.py:260:stop] epoch=0/micro_step=1570/global_step=1570, RunningAvgSamplesPerSec=7736.467401986201, CurrSamplesPerSec=6659.6074228441, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:40,650] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:40,652] [INFO] [timer.py:260:stop] epoch=0/micro_step=1580/global_step=1580, RunningAvgSamplesPerSec=7736.708916957024, CurrSamplesPerSec=7753.768226458695, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:40,785] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:40,787] [INFO] [timer.py:260:stop] epoch=0/micro_step=1590/global_step=1590, RunningAvgSamplesPerSec=7738.912610455815, CurrSamplesPerSec=8157.396784878597, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:40,922] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:40,923] [INFO] [timer.py:260:stop] epoch=0/micro_step=1600/global_step=1600, RunningAvgSamplesPerSec=7740.783192764819, CurrSamplesPerSec=7175.308224853653, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:41,060] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:41,061] [INFO] [timer.py:260:stop] epoch=0/micro_step=1610/global_step=1610, RunningAvgSamplesPerSec=7742.248513419928, CurrSamplesPerSec=6824.514567549702, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:41,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:41,193] [INFO] [timer.py:260:stop] epoch=0/micro_step=1620/global_step=1620, RunningAvgSamplesPerSec=7745.674113468, CurrSamplesPerSec=7816.762936431671, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:41,327] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:41,328] [INFO] [timer.py:260:stop] epoch=0/micro_step=1630/global_step=1630, RunningAvgSamplesPerSec=7748.676440514373, CurrSamplesPerSec=7640.550365752996, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.940430  [44864/60000]\n",
      "[2023-11-20 16:03:41,459] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:41,460] [INFO] [timer.py:260:stop] epoch=0/micro_step=1640/global_step=1640, RunningAvgSamplesPerSec=7752.765696445906, CurrSamplesPerSec=6970.719987535382, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:41,595] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:41,596] [INFO] [timer.py:260:stop] epoch=0/micro_step=1650/global_step=1650, RunningAvgSamplesPerSec=7756.370279805494, CurrSamplesPerSec=7372.5750068662455, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:41,735] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:41,737] [INFO] [timer.py:260:stop] epoch=0/micro_step=1660/global_step=1660, RunningAvgSamplesPerSec=7756.226708811994, CurrSamplesPerSec=7386.166689596346, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:41,870] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:41,870] [INFO] [timer.py:260:stop] epoch=0/micro_step=1670/global_step=1670, RunningAvgSamplesPerSec=7759.064896197568, CurrSamplesPerSec=7326.695125279764, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:42,005] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,006] [INFO] [timer.py:260:stop] epoch=0/micro_step=1680/global_step=1680, RunningAvgSamplesPerSec=7761.560869720673, CurrSamplesPerSec=7882.640981969813, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:42,140] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,141] [INFO] [timer.py:260:stop] epoch=0/micro_step=1690/global_step=1690, RunningAvgSamplesPerSec=7763.620455757277, CurrSamplesPerSec=6597.410931970114, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:42,272] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,273] [INFO] [timer.py:260:stop] epoch=0/micro_step=1700/global_step=1700, RunningAvgSamplesPerSec=7767.918224166949, CurrSamplesPerSec=8010.368416340903, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:42,405] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,406] [INFO] [timer.py:260:stop] epoch=0/micro_step=1710/global_step=1710, RunningAvgSamplesPerSec=7771.407708137118, CurrSamplesPerSec=7777.581734948137, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:42,537] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,538] [INFO] [timer.py:260:stop] epoch=0/micro_step=1720/global_step=1720, RunningAvgSamplesPerSec=7774.685848936273, CurrSamplesPerSec=7115.20810029952, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:42,673] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,674] [INFO] [timer.py:260:stop] epoch=0/micro_step=1730/global_step=1730, RunningAvgSamplesPerSec=7776.581370424261, CurrSamplesPerSec=7050.54647650566, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.950195  [51264/60000]\n",
      "[2023-11-20 16:03:42,809] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,810] [INFO] [timer.py:260:stop] epoch=0/micro_step=1740/global_step=1740, RunningAvgSamplesPerSec=7778.402946137865, CurrSamplesPerSec=7801.995465907109, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:42,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:42,949] [INFO] [timer.py:260:stop] epoch=0/micro_step=1750/global_step=1750, RunningAvgSamplesPerSec=7778.550274853887, CurrSamplesPerSec=6711.893183977597, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:43,086] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:43,087] [INFO] [timer.py:260:stop] epoch=0/micro_step=1760/global_step=1760, RunningAvgSamplesPerSec=7780.35262813569, CurrSamplesPerSec=7161.907526480083, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:43,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:43,226] [INFO] [timer.py:260:stop] epoch=0/micro_step=1770/global_step=1770, RunningAvgSamplesPerSec=7781.862216534106, CurrSamplesPerSec=7085.159975717264, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:43,364] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:43,365] [INFO] [timer.py:260:stop] epoch=0/micro_step=1780/global_step=1780, RunningAvgSamplesPerSec=7782.689839604544, CurrSamplesPerSec=7139.050982686631, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:43,513] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:43,514] [INFO] [timer.py:260:stop] epoch=0/micro_step=1790/global_step=1790, RunningAvgSamplesPerSec=7779.714029269371, CurrSamplesPerSec=6519.537960849079, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:43,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:43,662] [INFO] [timer.py:260:stop] epoch=0/micro_step=1800/global_step=1800, RunningAvgSamplesPerSec=7776.065646938998, CurrSamplesPerSec=6823.473716319268, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:43,797] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:43,798] [INFO] [timer.py:260:stop] epoch=0/micro_step=1810/global_step=1810, RunningAvgSamplesPerSec=7777.630718034778, CurrSamplesPerSec=7181.450975146473, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:43,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:43,938] [INFO] [timer.py:260:stop] epoch=0/micro_step=1820/global_step=1820, RunningAvgSamplesPerSec=7778.434249961048, CurrSamplesPerSec=7814.48738028005, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:44,068] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:44,069] [INFO] [timer.py:260:stop] epoch=0/micro_step=1830/global_step=1830, RunningAvgSamplesPerSec=7782.404755199842, CurrSamplesPerSec=7115.019508057676, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.879883  [57664/60000]\n",
      "[2023-11-20 16:03:44,203] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:44,204] [INFO] [timer.py:260:stop] epoch=0/micro_step=1840/global_step=1840, RunningAvgSamplesPerSec=7785.81801814355, CurrSamplesPerSec=7208.256068743287, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:44,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=1850, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:44,337] [INFO] [timer.py:260:stop] epoch=0/micro_step=1850/global_step=1850, RunningAvgSamplesPerSec=7788.477835108141, CurrSamplesPerSec=7250.113598919649, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:44,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=1860, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:44,469] [INFO] [timer.py:260:stop] epoch=0/micro_step=1860/global_step=1860, RunningAvgSamplesPerSec=7792.103086161537, CurrSamplesPerSec=7023.24523167892, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:44,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=1870, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:44,601] [INFO] [timer.py:260:stop] epoch=0/micro_step=1870/global_step=1870, RunningAvgSamplesPerSec=7795.2787363997395, CurrSamplesPerSec=7655.149033251582, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 1.878359 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.913086  [   64/60000]\n",
      "[2023-11-20 16:03:45,683] [INFO] [logging.py:96:log_dist] [Rank 0] step=1880, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:45,684] [INFO] [timer.py:260:stop] epoch=0/micro_step=1880/global_step=1880, RunningAvgSamplesPerSec=7797.168337595221, CurrSamplesPerSec=8360.652069642134, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:45,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=1890, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:45,823] [INFO] [timer.py:260:stop] epoch=0/micro_step=1890/global_step=1890, RunningAvgSamplesPerSec=7797.184532444142, CurrSamplesPerSec=7835.472605738638, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:45,961] [INFO] [logging.py:96:log_dist] [Rank 0] step=1900, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:45,962] [INFO] [timer.py:260:stop] epoch=0/micro_step=1900/global_step=1900, RunningAvgSamplesPerSec=7797.777429557284, CurrSamplesPerSec=7699.502524093621, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:46,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=1910, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:46,097] [INFO] [timer.py:260:stop] epoch=0/micro_step=1910/global_step=1910, RunningAvgSamplesPerSec=7799.699397555565, CurrSamplesPerSec=7393.286768756197, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:46,237] [INFO] [logging.py:96:log_dist] [Rank 0] step=1920, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:46,238] [INFO] [timer.py:260:stop] epoch=0/micro_step=1920/global_step=1920, RunningAvgSamplesPerSec=7799.710538093901, CurrSamplesPerSec=7035.209560750603, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:46,376] [INFO] [logging.py:96:log_dist] [Rank 0] step=1930, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:46,377] [INFO] [timer.py:260:stop] epoch=0/micro_step=1930/global_step=1930, RunningAvgSamplesPerSec=7800.447600513722, CurrSamplesPerSec=8128.988431954454, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:46,514] [INFO] [logging.py:96:log_dist] [Rank 0] step=1940, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:46,515] [INFO] [timer.py:260:stop] epoch=0/micro_step=1940/global_step=1940, RunningAvgSamplesPerSec=7800.60436487422, CurrSamplesPerSec=6538.753708620564, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:46,654] [INFO] [logging.py:96:log_dist] [Rank 0] step=1950, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:46,655] [INFO] [timer.py:260:stop] epoch=0/micro_step=1950/global_step=1950, RunningAvgSamplesPerSec=7801.6332212574225, CurrSamplesPerSec=7976.80542018305, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:46,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=1960, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:46,789] [INFO] [timer.py:260:stop] epoch=0/micro_step=1960/global_step=1960, RunningAvgSamplesPerSec=7804.303498899914, CurrSamplesPerSec=8414.113280882675, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:46,923] [INFO] [logging.py:96:log_dist] [Rank 0] step=1970, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:46,924] [INFO] [timer.py:260:stop] epoch=0/micro_step=1970/global_step=1970, RunningAvgSamplesPerSec=7805.527671089608, CurrSamplesPerSec=6904.204115226337, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.887695  [ 6464/60000]\n",
      "[2023-11-20 16:03:47,062] [INFO] [logging.py:96:log_dist] [Rank 0] step=1980, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:47,063] [INFO] [timer.py:260:stop] epoch=0/micro_step=1980/global_step=1980, RunningAvgSamplesPerSec=7806.174928278107, CurrSamplesPerSec=7377.437915681856, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:47,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=1990, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:47,201] [INFO] [timer.py:260:stop] epoch=0/micro_step=1990/global_step=1990, RunningAvgSamplesPerSec=7806.9200516788715, CurrSamplesPerSec=8190.00048816207, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:47,332] [INFO] [logging.py:96:log_dist] [Rank 0] step=2000, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:47,334] [INFO] [timer.py:260:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=7809.416566849204, CurrSamplesPerSec=8169.561628827074, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:47,465] [INFO] [logging.py:96:log_dist] [Rank 0] step=2010, skipped=18, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:47,466] [INFO] [timer.py:260:stop] epoch=0/micro_step=2010/global_step=2010, RunningAvgSamplesPerSec=7812.251192610322, CurrSamplesPerSec=8308.894542978302, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:47,587] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2023-11-20 16:03:47,600] [INFO] [logging.py:96:log_dist] [Rank 0] step=2020, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:47,601] [INFO] [timer.py:260:stop] epoch=0/micro_step=2020/global_step=2020, RunningAvgSamplesPerSec=7814.859520108893, CurrSamplesPerSec=8490.493927125506, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:47,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=2030, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:47,734] [INFO] [timer.py:260:stop] epoch=0/micro_step=2030/global_step=2030, RunningAvgSamplesPerSec=7818.0361651618505, CurrSamplesPerSec=7340.920939645035, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:47,870] [INFO] [logging.py:96:log_dist] [Rank 0] step=2040, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:47,871] [INFO] [timer.py:260:stop] epoch=0/micro_step=2040/global_step=2040, RunningAvgSamplesPerSec=7819.679214735749, CurrSamplesPerSec=6024.540610902888, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:48,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=2050, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,007] [INFO] [timer.py:260:stop] epoch=0/micro_step=2050/global_step=2050, RunningAvgSamplesPerSec=7821.340615361918, CurrSamplesPerSec=8143.0443197330505, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:48,139] [INFO] [logging.py:96:log_dist] [Rank 0] step=2060, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,140] [INFO] [timer.py:260:stop] epoch=0/micro_step=2060/global_step=2060, RunningAvgSamplesPerSec=7823.292551386295, CurrSamplesPerSec=6887.905573232064, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:48,274] [INFO] [logging.py:96:log_dist] [Rank 0] step=2070, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,276] [INFO] [timer.py:260:stop] epoch=0/micro_step=2070/global_step=2070, RunningAvgSamplesPerSec=7824.27892656199, CurrSamplesPerSec=6540.506213147508, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.770508  [12864/60000]\n",
      "[2023-11-20 16:03:48,411] [INFO] [logging.py:96:log_dist] [Rank 0] step=2080, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,412] [INFO] [timer.py:260:stop] epoch=0/micro_step=2080/global_step=2080, RunningAvgSamplesPerSec=7824.9447379858675, CurrSamplesPerSec=7728.097193032964, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:48,545] [INFO] [logging.py:96:log_dist] [Rank 0] step=2090, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,546] [INFO] [timer.py:260:stop] epoch=0/micro_step=2090/global_step=2090, RunningAvgSamplesPerSec=7826.942960502843, CurrSamplesPerSec=7569.878345224331, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:48,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=2100, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,680] [INFO] [timer.py:260:stop] epoch=0/micro_step=2100/global_step=2100, RunningAvgSamplesPerSec=7829.261515387739, CurrSamplesPerSec=8102.978024631731, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:48,817] [INFO] [logging.py:96:log_dist] [Rank 0] step=2110, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,818] [INFO] [timer.py:260:stop] epoch=0/micro_step=2110/global_step=2110, RunningAvgSamplesPerSec=7830.347931721969, CurrSamplesPerSec=6627.545021356443, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:48,955] [INFO] [logging.py:96:log_dist] [Rank 0] step=2120, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:48,956] [INFO] [timer.py:260:stop] epoch=0/micro_step=2120/global_step=2120, RunningAvgSamplesPerSec=7831.337333330928, CurrSamplesPerSec=7486.486390004462, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:49,091] [INFO] [logging.py:96:log_dist] [Rank 0] step=2130, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:49,092] [INFO] [timer.py:260:stop] epoch=0/micro_step=2130/global_step=2130, RunningAvgSamplesPerSec=7832.604427860593, CurrSamplesPerSec=7469.404418721131, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:49,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=2140, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:49,231] [INFO] [timer.py:260:stop] epoch=0/micro_step=2140/global_step=2140, RunningAvgSamplesPerSec=7833.416869323788, CurrSamplesPerSec=8203.265470769795, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:49,379] [INFO] [logging.py:96:log_dist] [Rank 0] step=2150, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:49,380] [INFO] [timer.py:260:stop] epoch=0/micro_step=2150/global_step=2150, RunningAvgSamplesPerSec=7831.284332709183, CurrSamplesPerSec=6992.691882880066, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:49,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=2160, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:49,529] [INFO] [timer.py:260:stop] epoch=0/micro_step=2160/global_step=2160, RunningAvgSamplesPerSec=7827.06483583415, CurrSamplesPerSec=5632.891742734236, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:49,677] [INFO] [logging.py:96:log_dist] [Rank 0] step=2170, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:49,678] [INFO] [timer.py:260:stop] epoch=0/micro_step=2170/global_step=2170, RunningAvgSamplesPerSec=7824.4119155606595, CurrSamplesPerSec=6714.243521760881, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.812500  [19264/60000]\n",
      "[2023-11-20 16:03:49,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=2180, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:49,814] [INFO] [timer.py:260:stop] epoch=0/micro_step=2180/global_step=2180, RunningAvgSamplesPerSec=7825.359619633286, CurrSamplesPerSec=7481.061702246252, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:49,955] [INFO] [logging.py:96:log_dist] [Rank 0] step=2190, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:49,956] [INFO] [timer.py:260:stop] epoch=0/micro_step=2190/global_step=2190, RunningAvgSamplesPerSec=7824.398425338838, CurrSamplesPerSec=7170.3249726206695, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:50,090] [INFO] [logging.py:96:log_dist] [Rank 0] step=2200, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:50,091] [INFO] [timer.py:260:stop] epoch=0/micro_step=2200/global_step=2200, RunningAvgSamplesPerSec=7826.554538990333, CurrSamplesPerSec=8178.273040246168, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:50,221] [INFO] [logging.py:96:log_dist] [Rank 0] step=2210, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:50,221] [INFO] [timer.py:260:stop] epoch=0/micro_step=2210/global_step=2210, RunningAvgSamplesPerSec=7829.8370470772825, CurrSamplesPerSec=8401.998685404864, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:50,348] [INFO] [logging.py:96:log_dist] [Rank 0] step=2220, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:50,348] [INFO] [timer.py:260:stop] epoch=0/micro_step=2220/global_step=2220, RunningAvgSamplesPerSec=7834.200352368712, CurrSamplesPerSec=8071.304828913344, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:50,480] [INFO] [logging.py:96:log_dist] [Rank 0] step=2230, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:50,481] [INFO] [timer.py:260:stop] epoch=0/micro_step=2230/global_step=2230, RunningAvgSamplesPerSec=7837.112947301456, CurrSamplesPerSec=8128.496124031008, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:50,610] [INFO] [logging.py:96:log_dist] [Rank 0] step=2240, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:50,611] [INFO] [timer.py:260:stop] epoch=0/micro_step=2240/global_step=2240, RunningAvgSamplesPerSec=7840.882361225895, CurrSamplesPerSec=8028.336403876062, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:50,739] [INFO] [logging.py:96:log_dist] [Rank 0] step=2250, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:50,740] [INFO] [timer.py:260:stop] epoch=0/micro_step=2250/global_step=2250, RunningAvgSamplesPerSec=7844.7776448105515, CurrSamplesPerSec=7569.664880717388, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:50,868] [INFO] [logging.py:96:log_dist] [Rank 0] step=2260, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:50,869] [INFO] [timer.py:260:stop] epoch=0/micro_step=2260/global_step=2260, RunningAvgSamplesPerSec=7848.030579244323, CurrSamplesPerSec=8104.935265700483, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:51,002] [INFO] [logging.py:96:log_dist] [Rank 0] step=2270, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,003] [INFO] [timer.py:260:stop] epoch=0/micro_step=2270/global_step=2270, RunningAvgSamplesPerSec=7849.783667776777, CurrSamplesPerSec=8412.53113541634, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.706055  [25664/60000]\n",
      "[2023-11-20 16:03:51,131] [INFO] [logging.py:96:log_dist] [Rank 0] step=2280, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,132] [INFO] [timer.py:260:stop] epoch=0/micro_step=2280/global_step=2280, RunningAvgSamplesPerSec=7853.2998636457805, CurrSamplesPerSec=8001.5338023131035, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:51,257] [INFO] [logging.py:96:log_dist] [Rank 0] step=2290, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,258] [INFO] [timer.py:260:stop] epoch=0/micro_step=2290/global_step=2290, RunningAvgSamplesPerSec=7857.468017123228, CurrSamplesPerSec=8271.259505762002, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:51,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=2300, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,386] [INFO] [timer.py:260:stop] epoch=0/micro_step=2300/global_step=2300, RunningAvgSamplesPerSec=7861.0964237099615, CurrSamplesPerSec=8050.487523992322, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:51,512] [INFO] [logging.py:96:log_dist] [Rank 0] step=2310, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,512] [INFO] [timer.py:260:stop] epoch=0/micro_step=2310/global_step=2310, RunningAvgSamplesPerSec=7865.360964112582, CurrSamplesPerSec=8462.122690876993, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:51,638] [INFO] [logging.py:96:log_dist] [Rank 0] step=2320, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,639] [INFO] [timer.py:260:stop] epoch=0/micro_step=2320/global_step=2320, RunningAvgSamplesPerSec=7869.438016419177, CurrSamplesPerSec=8134.900781865567, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:51,774] [INFO] [logging.py:96:log_dist] [Rank 0] step=2330, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,775] [INFO] [timer.py:260:stop] epoch=0/micro_step=2330/global_step=2330, RunningAvgSamplesPerSec=7870.392379973721, CurrSamplesPerSec=5658.181695544033, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:51,902] [INFO] [logging.py:96:log_dist] [Rank 0] step=2340, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:51,903] [INFO] [timer.py:260:stop] epoch=0/micro_step=2340/global_step=2340, RunningAvgSamplesPerSec=7873.738082784051, CurrSamplesPerSec=8134.900781865567, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:52,028] [INFO] [logging.py:96:log_dist] [Rank 0] step=2350, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,029] [INFO] [timer.py:260:stop] epoch=0/micro_step=2350/global_step=2350, RunningAvgSamplesPerSec=7877.719303465657, CurrSamplesPerSec=7418.828068429925, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:52,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=2360, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,156] [INFO] [timer.py:260:stop] epoch=0/micro_step=2360/global_step=2360, RunningAvgSamplesPerSec=7881.529215791891, CurrSamplesPerSec=7887.504951076896, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:52,285] [INFO] [logging.py:96:log_dist] [Rank 0] step=2370, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,286] [INFO] [timer.py:260:stop] epoch=0/micro_step=2370/global_step=2370, RunningAvgSamplesPerSec=7884.31425042542, CurrSamplesPerSec=8063.304076176744, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.652344  [32064/60000]\n",
      "[2023-11-20 16:03:52,415] [INFO] [logging.py:96:log_dist] [Rank 0] step=2380, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,416] [INFO] [timer.py:260:stop] epoch=0/micro_step=2380/global_step=2380, RunningAvgSamplesPerSec=7887.666543496695, CurrSamplesPerSec=8352.587466550502, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:52,543] [INFO] [logging.py:96:log_dist] [Rank 0] step=2390, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,544] [INFO] [timer.py:260:stop] epoch=0/micro_step=2390/global_step=2390, RunningAvgSamplesPerSec=7890.80863015025, CurrSamplesPerSec=7823.825590206937, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:52,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=2400, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,671] [INFO] [timer.py:260:stop] epoch=0/micro_step=2400/global_step=2400, RunningAvgSamplesPerSec=7894.31886950383, CurrSamplesPerSec=8555.166395767601, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:52,798] [INFO] [logging.py:96:log_dist] [Rank 0] step=2410, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,799] [INFO] [timer.py:260:stop] epoch=0/micro_step=2410/global_step=2410, RunningAvgSamplesPerSec=7897.651927423068, CurrSamplesPerSec=7921.721536917901, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:52,927] [INFO] [logging.py:96:log_dist] [Rank 0] step=2420, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:52,928] [INFO] [timer.py:260:stop] epoch=0/micro_step=2420/global_step=2420, RunningAvgSamplesPerSec=7900.38559180878, CurrSamplesPerSec=7926.867942357666, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:53,060] [INFO] [logging.py:96:log_dist] [Rank 0] step=2430, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,061] [INFO] [timer.py:260:stop] epoch=0/micro_step=2430/global_step=2430, RunningAvgSamplesPerSec=7902.6720871531, CurrSamplesPerSec=8021.858649852075, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:53,191] [INFO] [logging.py:96:log_dist] [Rank 0] step=2440, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,192] [INFO] [timer.py:260:stop] epoch=0/micro_step=2440/global_step=2440, RunningAvgSamplesPerSec=7904.9443793925075, CurrSamplesPerSec=7982.735777797603, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:53,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=2450, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,322] [INFO] [timer.py:260:stop] epoch=0/micro_step=2450/global_step=2450, RunningAvgSamplesPerSec=7907.768797599758, CurrSamplesPerSec=7970.6471880753015, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:53,450] [INFO] [logging.py:96:log_dist] [Rank 0] step=2460, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,451] [INFO] [timer.py:260:stop] epoch=0/micro_step=2460/global_step=2460, RunningAvgSamplesPerSec=7911.032706480956, CurrSamplesPerSec=7344.938189181054, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:53,580] [INFO] [logging.py:96:log_dist] [Rank 0] step=2470, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,581] [INFO] [timer.py:260:stop] epoch=0/micro_step=2470/global_step=2470, RunningAvgSamplesPerSec=7913.8465493913145, CurrSamplesPerSec=7765.20744019208, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.682617  [38464/60000]\n",
      "[2023-11-20 16:03:53,711] [INFO] [logging.py:96:log_dist] [Rank 0] step=2480, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,712] [INFO] [timer.py:260:stop] epoch=0/micro_step=2480/global_step=2480, RunningAvgSamplesPerSec=7916.7687426775165, CurrSamplesPerSec=8261.077614328799, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:53,839] [INFO] [logging.py:96:log_dist] [Rank 0] step=2490, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,840] [INFO] [timer.py:260:stop] epoch=0/micro_step=2490/global_step=2490, RunningAvgSamplesPerSec=7919.798616553924, CurrSamplesPerSec=8463.456695147712, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:53,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=2500, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:53,967] [INFO] [timer.py:260:stop] epoch=0/micro_step=2500/global_step=2500, RunningAvgSamplesPerSec=7923.037468773029, CurrSamplesPerSec=8722.233428645697, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:54,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=2510, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,097] [INFO] [timer.py:260:stop] epoch=0/micro_step=2510/global_step=2510, RunningAvgSamplesPerSec=7925.584632932329, CurrSamplesPerSec=6249.370396237836, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:54,221] [INFO] [logging.py:96:log_dist] [Rank 0] step=2520, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,222] [INFO] [timer.py:260:stop] epoch=0/micro_step=2520/global_step=2520, RunningAvgSamplesPerSec=7929.53453784855, CurrSamplesPerSec=8860.133214509688, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:54,348] [INFO] [logging.py:96:log_dist] [Rank 0] step=2530, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,349] [INFO] [timer.py:260:stop] epoch=0/micro_step=2530/global_step=2530, RunningAvgSamplesPerSec=7932.73463903392, CurrSamplesPerSec=7747.055007215007, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:54,475] [INFO] [logging.py:96:log_dist] [Rank 0] step=2540, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,476] [INFO] [timer.py:260:stop] epoch=0/micro_step=2540/global_step=2540, RunningAvgSamplesPerSec=7936.654720077912, CurrSamplesPerSec=8775.842029554073, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:54,602] [INFO] [logging.py:96:log_dist] [Rank 0] step=2550, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,603] [INFO] [timer.py:260:stop] epoch=0/micro_step=2550/global_step=2550, RunningAvgSamplesPerSec=7939.918655033477, CurrSamplesPerSec=8305.295504470778, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:54,729] [INFO] [logging.py:96:log_dist] [Rank 0] step=2560, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,730] [INFO] [timer.py:260:stop] epoch=0/micro_step=2560/global_step=2560, RunningAvgSamplesPerSec=7943.743331413199, CurrSamplesPerSec=8254.726652111074, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:54,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=2570, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,858] [INFO] [timer.py:260:stop] epoch=0/micro_step=2570/global_step=2570, RunningAvgSamplesPerSec=7946.73350776034, CurrSamplesPerSec=7999.149412956672, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.582031  [44864/60000]\n",
      "[2023-11-20 16:03:54,994] [INFO] [logging.py:96:log_dist] [Rank 0] step=2580, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:54,995] [INFO] [timer.py:260:stop] epoch=0/micro_step=2580/global_step=2580, RunningAvgSamplesPerSec=7946.919804089316, CurrSamplesPerSec=8731.028004553586, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:55,119] [INFO] [logging.py:96:log_dist] [Rank 0] step=2590, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:55,120] [INFO] [timer.py:260:stop] epoch=0/micro_step=2590/global_step=2590, RunningAvgSamplesPerSec=7950.555945647117, CurrSamplesPerSec=8488.88292960597, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:55,246] [INFO] [logging.py:96:log_dist] [Rank 0] step=2600, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:55,247] [INFO] [timer.py:260:stop] epoch=0/micro_step=2600/global_step=2600, RunningAvgSamplesPerSec=7954.105514370675, CurrSamplesPerSec=8398.31855583018, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:55,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=2610, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:55,380] [INFO] [timer.py:260:stop] epoch=0/micro_step=2610/global_step=2610, RunningAvgSamplesPerSec=7955.616589191188, CurrSamplesPerSec=7821.318026864019, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:55,509] [INFO] [logging.py:96:log_dist] [Rank 0] step=2620, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:55,510] [INFO] [timer.py:260:stop] epoch=0/micro_step=2620/global_step=2620, RunningAvgSamplesPerSec=7958.005486843282, CurrSamplesPerSec=8189.250922846944, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:55,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=2630, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:55,636] [INFO] [timer.py:260:stop] epoch=0/micro_step=2630/global_step=2630, RunningAvgSamplesPerSec=7961.13609615165, CurrSamplesPerSec=8170.058923788653, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:55,774] [INFO] [logging.py:96:log_dist] [Rank 0] step=2640, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:55,775] [INFO] [timer.py:260:stop] epoch=0/micro_step=2640/global_step=2640, RunningAvgSamplesPerSec=7962.014870840635, CurrSamplesPerSec=8055.560903880203, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:55,908] [INFO] [logging.py:96:log_dist] [Rank 0] step=2650, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:55,909] [INFO] [timer.py:260:stop] epoch=0/micro_step=2650/global_step=2650, RunningAvgSamplesPerSec=7963.119136679722, CurrSamplesPerSec=7371.967593991157, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:56,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=2660, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,037] [INFO] [timer.py:260:stop] epoch=0/micro_step=2660/global_step=2660, RunningAvgSamplesPerSec=7965.610803342563, CurrSamplesPerSec=7235.84710766079, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:56,169] [INFO] [logging.py:96:log_dist] [Rank 0] step=2670, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,170] [INFO] [timer.py:260:stop] epoch=0/micro_step=2670/global_step=2670, RunningAvgSamplesPerSec=7967.027162416921, CurrSamplesPerSec=8136.380213385063, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.609375  [51264/60000]\n",
      "[2023-11-20 16:03:56,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=2680, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,296] [INFO] [timer.py:260:stop] epoch=0/micro_step=2680/global_step=2680, RunningAvgSamplesPerSec=7970.2655966856855, CurrSamplesPerSec=8460.522440746345, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:56,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=2690, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,422] [INFO] [timer.py:260:stop] epoch=0/micro_step=2690/global_step=2690, RunningAvgSamplesPerSec=7973.325266035345, CurrSamplesPerSec=7793.614261243213, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:56,552] [INFO] [logging.py:96:log_dist] [Rank 0] step=2700, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,553] [INFO] [timer.py:260:stop] epoch=0/micro_step=2700/global_step=2700, RunningAvgSamplesPerSec=7975.43456009315, CurrSamplesPerSec=8324.612541090368, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:56,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=2710, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,680] [INFO] [timer.py:260:stop] epoch=0/micro_step=2710/global_step=2710, RunningAvgSamplesPerSec=7978.282367299082, CurrSamplesPerSec=8250.920759820496, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:56,808] [INFO] [logging.py:96:log_dist] [Rank 0] step=2720, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,809] [INFO] [timer.py:260:stop] epoch=0/micro_step=2720/global_step=2720, RunningAvgSamplesPerSec=7980.917507079955, CurrSamplesPerSec=7869.238273921201, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:56,936] [INFO] [logging.py:96:log_dist] [Rank 0] step=2730, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:56,936] [INFO] [timer.py:260:stop] epoch=0/micro_step=2730/global_step=2730, RunningAvgSamplesPerSec=7983.671526915223, CurrSamplesPerSec=7450.1250589769925, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:57,062] [INFO] [logging.py:96:log_dist] [Rank 0] step=2740, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,063] [INFO] [timer.py:260:stop] epoch=0/micro_step=2740/global_step=2740, RunningAvgSamplesPerSec=7986.660982095871, CurrSamplesPerSec=8193.000122085215, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:57,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=2750, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,193] [INFO] [timer.py:260:stop] epoch=0/micro_step=2750/global_step=2750, RunningAvgSamplesPerSec=7988.590435274491, CurrSamplesPerSec=8078.348912094857, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:57,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=2760, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,323] [INFO] [timer.py:260:stop] epoch=0/micro_step=2760/global_step=2760, RunningAvgSamplesPerSec=7990.788837622964, CurrSamplesPerSec=8290.93047533743, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:57,451] [INFO] [logging.py:96:log_dist] [Rank 0] step=2770, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,452] [INFO] [timer.py:260:stop] epoch=0/micro_step=2770/global_step=2770, RunningAvgSamplesPerSec=7992.70223255756, CurrSamplesPerSec=7911.215584568684, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.513672  [57664/60000]\n",
      "[2023-11-20 16:03:57,587] [INFO] [logging.py:96:log_dist] [Rank 0] step=2780, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,588] [INFO] [timer.py:260:stop] epoch=0/micro_step=2780/global_step=2780, RunningAvgSamplesPerSec=7993.589817925083, CurrSamplesPerSec=8065.24219571553, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:57,716] [INFO] [logging.py:96:log_dist] [Rank 0] step=2790, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,717] [INFO] [timer.py:260:stop] epoch=0/micro_step=2790/global_step=2790, RunningAvgSamplesPerSec=7996.166823039644, CurrSamplesPerSec=8338.576540755466, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:57,852] [INFO] [logging.py:96:log_dist] [Rank 0] step=2800, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,853] [INFO] [timer.py:260:stop] epoch=0/micro_step=2800/global_step=2800, RunningAvgSamplesPerSec=7996.951375820886, CurrSamplesPerSec=7140.1903444607, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:57,986] [INFO] [logging.py:96:log_dist] [Rank 0] step=2810, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:57,987] [INFO] [timer.py:260:stop] epoch=0/micro_step=2810/global_step=2810, RunningAvgSamplesPerSec=7997.767406667494, CurrSamplesPerSec=6978.875207986689, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.529123 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.597656  [   64/60000]\n",
      "[2023-11-20 16:03:59,017] [INFO] [logging.py:96:log_dist] [Rank 0] step=2820, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,017] [INFO] [timer.py:260:stop] epoch=0/micro_step=2820/global_step=2820, RunningAvgSamplesPerSec=8000.010861343175, CurrSamplesPerSec=7996.766444232602, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:59,150] [INFO] [logging.py:96:log_dist] [Rank 0] step=2830, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,151] [INFO] [timer.py:260:stop] epoch=0/micro_step=2830/global_step=2830, RunningAvgSamplesPerSec=8000.995588559821, CurrSamplesPerSec=7072.279903045632, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:59,284] [INFO] [logging.py:96:log_dist] [Rank 0] step=2840, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,285] [INFO] [timer.py:260:stop] epoch=0/micro_step=2840/global_step=2840, RunningAvgSamplesPerSec=8002.206779856607, CurrSamplesPerSec=8149.966785074536, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:59,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=2850, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,424] [INFO] [timer.py:260:stop] epoch=0/micro_step=2850/global_step=2850, RunningAvgSamplesPerSec=8002.033632599034, CurrSamplesPerSec=7387.7929269299575, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:59,555] [INFO] [logging.py:96:log_dist] [Rank 0] step=2860, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,556] [INFO] [timer.py:260:stop] epoch=0/micro_step=2860/global_step=2860, RunningAvgSamplesPerSec=8003.164147558688, CurrSamplesPerSec=6547.36593575453, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:59,695] [INFO] [logging.py:96:log_dist] [Rank 0] step=2870, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,696] [INFO] [timer.py:260:stop] epoch=0/micro_step=2870/global_step=2870, RunningAvgSamplesPerSec=8002.628619894196, CurrSamplesPerSec=7338.713324949423, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:59,839] [INFO] [logging.py:96:log_dist] [Rank 0] step=2880, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,840] [INFO] [timer.py:260:stop] epoch=0/micro_step=2880/global_step=2880, RunningAvgSamplesPerSec=8001.968000279246, CurrSamplesPerSec=7091.149280147933, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:03:59,977] [INFO] [logging.py:96:log_dist] [Rank 0] step=2890, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:03:59,978] [INFO] [timer.py:260:stop] epoch=0/micro_step=2890/global_step=2890, RunningAvgSamplesPerSec=8002.078250015442, CurrSamplesPerSec=7657.332724783204, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:00,112] [INFO] [logging.py:96:log_dist] [Rank 0] step=2900, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:00,113] [INFO] [timer.py:260:stop] epoch=0/micro_step=2900/global_step=2900, RunningAvgSamplesPerSec=8003.178114421752, CurrSamplesPerSec=8273.298896628245, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:00,254] [INFO] [logging.py:96:log_dist] [Rank 0] step=2910, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:00,255] [INFO] [timer.py:260:stop] epoch=0/micro_step=2910/global_step=2910, RunningAvgSamplesPerSec=8002.315679743148, CurrSamplesPerSec=7436.503199711888, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.565430  [ 6464/60000]\n",
      "[2023-11-20 16:04:00,391] [INFO] [logging.py:96:log_dist] [Rank 0] step=2920, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:00,392] [INFO] [timer.py:260:stop] epoch=0/micro_step=2920/global_step=2920, RunningAvgSamplesPerSec=8002.50111901433, CurrSamplesPerSec=7445.372385865646, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:00,526] [INFO] [logging.py:96:log_dist] [Rank 0] step=2930, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:00,528] [INFO] [timer.py:260:stop] epoch=0/micro_step=2930/global_step=2930, RunningAvgSamplesPerSec=8002.42619644811, CurrSamplesPerSec=7664.110092790864, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:00,657] [INFO] [logging.py:96:log_dist] [Rank 0] step=2940, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:00,658] [INFO] [timer.py:260:stop] epoch=0/micro_step=2940/global_step=2940, RunningAvgSamplesPerSec=8004.165177877263, CurrSamplesPerSec=8051.936408902754, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:00,791] [INFO] [logging.py:96:log_dist] [Rank 0] step=2950, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:00,792] [INFO] [timer.py:260:stop] epoch=0/micro_step=2950/global_step=2950, RunningAvgSamplesPerSec=8005.110137603115, CurrSamplesPerSec=7902.132940830144, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:00,929] [INFO] [logging.py:96:log_dist] [Rank 0] step=2960, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:00,930] [INFO] [timer.py:260:stop] epoch=0/micro_step=2960/global_step=2960, RunningAvgSamplesPerSec=8005.0196789812335, CurrSamplesPerSec=7908.651699958753, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:01,065] [INFO] [logging.py:96:log_dist] [Rank 0] step=2970, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,066] [INFO] [timer.py:260:stop] epoch=0/micro_step=2970/global_step=2970, RunningAvgSamplesPerSec=8005.472441023683, CurrSamplesPerSec=7759.595768052263, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:01,198] [INFO] [logging.py:96:log_dist] [Rank 0] step=2980, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,199] [INFO] [timer.py:260:stop] epoch=0/micro_step=2980/global_step=2980, RunningAvgSamplesPerSec=8006.123786990566, CurrSamplesPerSec=6991.417007422841, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:01,332] [INFO] [logging.py:96:log_dist] [Rank 0] step=2990, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,333] [INFO] [timer.py:260:stop] epoch=0/micro_step=2990/global_step=2990, RunningAvgSamplesPerSec=8006.898124194891, CurrSamplesPerSec=7547.742330943343, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:01,463] [INFO] [logging.py:96:log_dist] [Rank 0] step=3000, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,464] [INFO] [timer.py:260:stop] epoch=0/micro_step=3000/global_step=3000, RunningAvgSamplesPerSec=8008.432270241654, CurrSamplesPerSec=8166.082258457045, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:01,601] [INFO] [logging.py:96:log_dist] [Rank 0] step=3010, skipped=19, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,602] [INFO] [timer.py:260:stop] epoch=0/micro_step=3010/global_step=3010, RunningAvgSamplesPerSec=8007.59160737793, CurrSamplesPerSec=7511.205327662432, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.422852  [12864/60000]\n",
      "[2023-11-20 16:04:01,731] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2023-11-20 16:04:01,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=3020, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,733] [INFO] [timer.py:260:stop] epoch=0/micro_step=3020/global_step=3020, RunningAvgSamplesPerSec=8009.245781019059, CurrSamplesPerSec=8891.830004306205, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:01,860] [INFO] [logging.py:96:log_dist] [Rank 0] step=3030, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,861] [INFO] [timer.py:260:stop] epoch=0/micro_step=3030/global_step=3030, RunningAvgSamplesPerSec=8011.308807285736, CurrSamplesPerSec=8898.904558262888, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:01,992] [INFO] [logging.py:96:log_dist] [Rank 0] step=3040, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:01,994] [INFO] [timer.py:260:stop] epoch=0/micro_step=3040/global_step=3040, RunningAvgSamplesPerSec=8012.415309861691, CurrSamplesPerSec=6973.436275783239, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:02,124] [INFO] [logging.py:96:log_dist] [Rank 0] step=3050, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:02,125] [INFO] [timer.py:260:stop] epoch=0/micro_step=3050/global_step=3050, RunningAvgSamplesPerSec=8013.937915570137, CurrSamplesPerSec=8247.371758633402, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:02,255] [INFO] [logging.py:96:log_dist] [Rank 0] step=3060, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:02,256] [INFO] [timer.py:260:stop] epoch=0/micro_step=3060/global_step=3060, RunningAvgSamplesPerSec=8015.142619662291, CurrSamplesPerSec=7146.463340610191, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:02,386] [INFO] [logging.py:96:log_dist] [Rank 0] step=3070, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:02,387] [INFO] [timer.py:260:stop] epoch=0/micro_step=3070/global_step=3070, RunningAvgSamplesPerSec=8016.295976964197, CurrSamplesPerSec=7318.904381492488, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:02,516] [INFO] [logging.py:96:log_dist] [Rank 0] step=3080, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:02,517] [INFO] [timer.py:260:stop] epoch=0/micro_step=3080/global_step=3080, RunningAvgSamplesPerSec=8017.702486225809, CurrSamplesPerSec=7117.471987272968, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:02,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=3090, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:02,648] [INFO] [timer.py:260:stop] epoch=0/micro_step=3090/global_step=3090, RunningAvgSamplesPerSec=8018.7683581432375, CurrSamplesPerSec=8319.968261839822, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:02,781] [INFO] [logging.py:96:log_dist] [Rank 0] step=3100, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:02,782] [INFO] [timer.py:260:stop] epoch=0/micro_step=3100/global_step=3100, RunningAvgSamplesPerSec=8019.413181681499, CurrSamplesPerSec=8212.300180499893, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:02,911] [INFO] [logging.py:96:log_dist] [Rank 0] step=3110, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:02,912] [INFO] [timer.py:260:stop] epoch=0/micro_step=3110/global_step=3110, RunningAvgSamplesPerSec=8021.0032808341975, CurrSamplesPerSec=7670.4610812664305, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.495117  [19264/60000]\n",
      "[2023-11-20 16:04:03,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=3120, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,038] [INFO] [timer.py:260:stop] epoch=0/micro_step=3120/global_step=3120, RunningAvgSamplesPerSec=8023.569752967307, CurrSamplesPerSec=8412.26750235036, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:03,176] [INFO] [logging.py:96:log_dist] [Rank 0] step=3130, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,177] [INFO] [timer.py:260:stop] epoch=0/micro_step=3130/global_step=3130, RunningAvgSamplesPerSec=8023.186620633355, CurrSamplesPerSec=7691.339961605685, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:03,304] [INFO] [logging.py:96:log_dist] [Rank 0] step=3140, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,305] [INFO] [timer.py:260:stop] epoch=0/micro_step=3140/global_step=3140, RunningAvgSamplesPerSec=8025.493577617403, CurrSamplesPerSec=8516.083119190382, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:03,437] [INFO] [logging.py:96:log_dist] [Rank 0] step=3150, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,438] [INFO] [timer.py:260:stop] epoch=0/micro_step=3150/global_step=3150, RunningAvgSamplesPerSec=8026.084893084844, CurrSamplesPerSec=7924.527838460176, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:03,570] [INFO] [logging.py:96:log_dist] [Rank 0] step=3160, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,571] [INFO] [timer.py:260:stop] epoch=0/micro_step=3160/global_step=3160, RunningAvgSamplesPerSec=8026.561362128453, CurrSamplesPerSec=7854.501872659176, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:03,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=3170, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,702] [INFO] [timer.py:260:stop] epoch=0/micro_step=3170/global_step=3170, RunningAvgSamplesPerSec=8027.949956663505, CurrSamplesPerSec=6646.416163216797, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:03,833] [INFO] [logging.py:96:log_dist] [Rank 0] step=3180, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,834] [INFO] [timer.py:260:stop] epoch=0/micro_step=3180/global_step=3180, RunningAvgSamplesPerSec=8029.104559137356, CurrSamplesPerSec=7537.780972705829, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:03,963] [INFO] [logging.py:96:log_dist] [Rank 0] step=3190, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:03,964] [INFO] [timer.py:260:stop] epoch=0/micro_step=3190/global_step=3190, RunningAvgSamplesPerSec=8030.740262502994, CurrSamplesPerSec=7159.806252000427, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:04,092] [INFO] [logging.py:96:log_dist] [Rank 0] step=3200, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:04,093] [INFO] [timer.py:260:stop] epoch=0/micro_step=3200/global_step=3200, RunningAvgSamplesPerSec=8032.576390464374, CurrSamplesPerSec=8413.322133767942, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:04,226] [INFO] [logging.py:96:log_dist] [Rank 0] step=3210, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:04,227] [INFO] [timer.py:260:stop] epoch=0/micro_step=3210/global_step=3210, RunningAvgSamplesPerSec=8032.693315614178, CurrSamplesPerSec=8337.540564045223, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.378906  [25664/60000]\n",
      "[2023-11-20 16:04:04,361] [INFO] [logging.py:96:log_dist] [Rank 0] step=3220, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:04,361] [INFO] [timer.py:260:stop] epoch=0/micro_step=3220/global_step=3220, RunningAvgSamplesPerSec=8033.29478501364, CurrSamplesPerSec=6364.4985655689115, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:04,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=3230, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:04,493] [INFO] [timer.py:260:stop] epoch=0/micro_step=3230/global_step=3230, RunningAvgSamplesPerSec=8034.335092352518, CurrSamplesPerSec=8394.9041781336, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:04,622] [INFO] [logging.py:96:log_dist] [Rank 0] step=3240, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:04,623] [INFO] [timer.py:260:stop] epoch=0/micro_step=3240/global_step=3240, RunningAvgSamplesPerSec=8035.819575561576, CurrSamplesPerSec=7689.136833662742, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:04,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=3250, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:04,756] [INFO] [timer.py:260:stop] epoch=0/micro_step=3250/global_step=3250, RunningAvgSamplesPerSec=8036.88709403276, CurrSamplesPerSec=8462.92304297109, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:04,890] [INFO] [logging.py:96:log_dist] [Rank 0] step=3260, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:04,891] [INFO] [timer.py:260:stop] epoch=0/micro_step=3260/global_step=3260, RunningAvgSamplesPerSec=8037.777691949597, CurrSamplesPerSec=8214.310597019492, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:05,023] [INFO] [logging.py:96:log_dist] [Rank 0] step=3270, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,025] [INFO] [timer.py:260:stop] epoch=0/micro_step=3270/global_step=3270, RunningAvgSamplesPerSec=8038.4042674489065, CurrSamplesPerSec=8366.64555541703, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:05,159] [INFO] [logging.py:96:log_dist] [Rank 0] step=3280, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,160] [INFO] [timer.py:260:stop] epoch=0/micro_step=3280/global_step=3280, RunningAvgSamplesPerSec=8038.110562906802, CurrSamplesPerSec=8076.404488973132, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:05,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=3290, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,296] [INFO] [timer.py:260:stop] epoch=0/micro_step=3290/global_step=3290, RunningAvgSamplesPerSec=8037.665976091787, CurrSamplesPerSec=5955.967517195474, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:05,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=3300, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,424] [INFO] [timer.py:260:stop] epoch=0/micro_step=3300/global_step=3300, RunningAvgSamplesPerSec=8039.661286732838, CurrSamplesPerSec=8853.996173890098, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:05,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=3310, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,559] [INFO] [timer.py:260:stop] epoch=0/micro_step=3310/global_step=3310, RunningAvgSamplesPerSec=8039.956897545185, CurrSamplesPerSec=7374.397846213016, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.372070  [32064/60000]\n",
      "[2023-11-20 16:04:05,691] [INFO] [logging.py:96:log_dist] [Rank 0] step=3320, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,692] [INFO] [timer.py:260:stop] epoch=0/micro_step=3320/global_step=3320, RunningAvgSamplesPerSec=8041.188386102676, CurrSamplesPerSec=8416.751512871162, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:05,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=3330, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,824] [INFO] [timer.py:260:stop] epoch=0/micro_step=3330/global_step=3330, RunningAvgSamplesPerSec=8042.1879016201465, CurrSamplesPerSec=8418.335246338633, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:05,963] [INFO] [logging.py:96:log_dist] [Rank 0] step=3340, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:05,964] [INFO] [timer.py:260:stop] epoch=0/micro_step=3340/global_step=3340, RunningAvgSamplesPerSec=8041.447618599067, CurrSamplesPerSec=7529.746311360449, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:06,100] [INFO] [logging.py:96:log_dist] [Rank 0] step=3350, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:06,101] [INFO] [timer.py:260:stop] epoch=0/micro_step=3350/global_step=3350, RunningAvgSamplesPerSec=8041.260824002905, CurrSamplesPerSec=7676.383539706597, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:06,233] [INFO] [logging.py:96:log_dist] [Rank 0] step=3360, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:06,235] [INFO] [timer.py:260:stop] epoch=0/micro_step=3360/global_step=3360, RunningAvgSamplesPerSec=8041.898134285454, CurrSamplesPerSec=7848.0720383580865, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:06,376] [INFO] [logging.py:96:log_dist] [Rank 0] step=3370, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:06,377] [INFO] [timer.py:260:stop] epoch=0/micro_step=3370/global_step=3370, RunningAvgSamplesPerSec=8040.781100380531, CurrSamplesPerSec=7425.395037481674, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:06,522] [INFO] [logging.py:96:log_dist] [Rank 0] step=3380, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:06,523] [INFO] [timer.py:260:stop] epoch=0/micro_step=3380/global_step=3380, RunningAvgSamplesPerSec=8039.188654388053, CurrSamplesPerSec=7151.41346973572, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:06,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=3390, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:06,662] [INFO] [timer.py:260:stop] epoch=0/micro_step=3390/global_step=3390, RunningAvgSamplesPerSec=8038.397282502464, CurrSamplesPerSec=6919.687984945737, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:06,800] [INFO] [logging.py:96:log_dist] [Rank 0] step=3400, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:06,801] [INFO] [timer.py:260:stop] epoch=0/micro_step=3400/global_step=3400, RunningAvgSamplesPerSec=8037.893256425632, CurrSamplesPerSec=6559.044519376435, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:06,942] [INFO] [logging.py:96:log_dist] [Rank 0] step=3410, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:06,943] [INFO] [timer.py:260:stop] epoch=0/micro_step=3410/global_step=3410, RunningAvgSamplesPerSec=8036.431803328994, CurrSamplesPerSec=7040.5606525559315, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.394531  [38464/60000]\n",
      "[2023-11-20 16:04:07,079] [INFO] [logging.py:96:log_dist] [Rank 0] step=3420, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:07,081] [INFO] [timer.py:260:stop] epoch=0/micro_step=3420/global_step=3420, RunningAvgSamplesPerSec=8036.883890249164, CurrSamplesPerSec=8604.25206744022, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:07,220] [INFO] [logging.py:96:log_dist] [Rank 0] step=3430, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:07,221] [INFO] [timer.py:260:stop] epoch=0/micro_step=3430/global_step=3430, RunningAvgSamplesPerSec=8036.253071674732, CurrSamplesPerSec=7530.168761220826, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:07,356] [INFO] [logging.py:96:log_dist] [Rank 0] step=3440, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:07,357] [INFO] [timer.py:260:stop] epoch=0/micro_step=3440/global_step=3440, RunningAvgSamplesPerSec=8036.465223633136, CurrSamplesPerSec=7828.38891805191, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:07,490] [INFO] [logging.py:96:log_dist] [Rank 0] step=3450, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:07,490] [INFO] [timer.py:260:stop] epoch=0/micro_step=3450/global_step=3450, RunningAvgSamplesPerSec=8037.17527072055, CurrSamplesPerSec=7714.770972840925, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:07,635] [INFO] [logging.py:96:log_dist] [Rank 0] step=3460, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:07,636] [INFO] [timer.py:260:stop] epoch=0/micro_step=3460/global_step=3460, RunningAvgSamplesPerSec=8035.597803915028, CurrSamplesPerSec=7506.584340044743, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:07,771] [INFO] [logging.py:96:log_dist] [Rank 0] step=3470, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:07,772] [INFO] [timer.py:260:stop] epoch=0/micro_step=3470/global_step=3470, RunningAvgSamplesPerSec=8035.937054395306, CurrSamplesPerSec=8062.335365670521, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:07,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=3480, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:07,906] [INFO] [timer.py:260:stop] epoch=0/micro_step=3480/global_step=3480, RunningAvgSamplesPerSec=8036.841991494424, CurrSamplesPerSec=7170.899609980232, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:08,046] [INFO] [logging.py:96:log_dist] [Rank 0] step=3490, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:08,047] [INFO] [timer.py:260:stop] epoch=0/micro_step=3490/global_step=3490, RunningAvgSamplesPerSec=8035.968539266748, CurrSamplesPerSec=6749.18804213914, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:08,207] [INFO] [logging.py:96:log_dist] [Rank 0] step=3500, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:08,208] [INFO] [timer.py:260:stop] epoch=0/micro_step=3500/global_step=3500, RunningAvgSamplesPerSec=8033.172346494789, CurrSamplesPerSec=6875.027686003329, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:08,342] [INFO] [logging.py:96:log_dist] [Rank 0] step=3510, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:08,343] [INFO] [timer.py:260:stop] epoch=0/micro_step=3510/global_step=3510, RunningAvgSamplesPerSec=8033.754317904289, CurrSamplesPerSec=7427.655118981737, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.317383  [44864/60000]\n",
      "[2023-11-20 16:04:08,476] [INFO] [logging.py:96:log_dist] [Rank 0] step=3520, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:08,477] [INFO] [timer.py:260:stop] epoch=0/micro_step=3520/global_step=3520, RunningAvgSamplesPerSec=8034.184260482381, CurrSamplesPerSec=6815.331352984487, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:08,622] [INFO] [logging.py:96:log_dist] [Rank 0] step=3530, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:08,623] [INFO] [timer.py:260:stop] epoch=0/micro_step=3530/global_step=3530, RunningAvgSamplesPerSec=8031.926735932119, CurrSamplesPerSec=6441.162711457709, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:08,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=3540, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:08,759] [INFO] [timer.py:260:stop] epoch=0/micro_step=3540/global_step=3540, RunningAvgSamplesPerSec=8032.361188512663, CurrSamplesPerSec=7539.898207965844, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:08,898] [INFO] [logging.py:96:log_dist] [Rank 0] step=3550, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:08,900] [INFO] [timer.py:260:stop] epoch=0/micro_step=3550/global_step=3550, RunningAvgSamplesPerSec=8031.657637248297, CurrSamplesPerSec=7105.790719220689, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:09,034] [INFO] [logging.py:96:log_dist] [Rank 0] step=3560, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,035] [INFO] [timer.py:260:stop] epoch=0/micro_step=3560/global_step=3560, RunningAvgSamplesPerSec=8031.958861552605, CurrSamplesPerSec=6674.178418697165, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:09,169] [INFO] [logging.py:96:log_dist] [Rank 0] step=3570, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,170] [INFO] [timer.py:260:stop] epoch=0/micro_step=3570/global_step=3570, RunningAvgSamplesPerSec=8032.351446852804, CurrSamplesPerSec=8151.699240813848, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:09,300] [INFO] [logging.py:96:log_dist] [Rank 0] step=3580, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,301] [INFO] [timer.py:260:stop] epoch=0/micro_step=3580/global_step=3580, RunningAvgSamplesPerSec=8033.629974337038, CurrSamplesPerSec=7244.634874369147, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:09,442] [INFO] [logging.py:96:log_dist] [Rank 0] step=3590, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,444] [INFO] [timer.py:260:stop] epoch=0/micro_step=3590/global_step=3590, RunningAvgSamplesPerSec=8033.113281964644, CurrSamplesPerSec=7591.2857668052375, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:09,580] [INFO] [logging.py:96:log_dist] [Rank 0] step=3600, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,581] [INFO] [timer.py:260:stop] epoch=0/micro_step=3600/global_step=3600, RunningAvgSamplesPerSec=8032.527311681347, CurrSamplesPerSec=6451.534704864449, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:09,714] [INFO] [logging.py:96:log_dist] [Rank 0] step=3610, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,714] [INFO] [timer.py:260:stop] epoch=0/micro_step=3610/global_step=3610, RunningAvgSamplesPerSec=8033.162743869555, CurrSamplesPerSec=7794.519469206423, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.351562  [51264/60000]\n",
      "[2023-11-20 16:04:09,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=3620, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,848] [INFO] [timer.py:260:stop] epoch=0/micro_step=3620/global_step=3620, RunningAvgSamplesPerSec=8034.175107819068, CurrSamplesPerSec=7860.251705660156, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:09,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=3630, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:09,984] [INFO] [timer.py:260:stop] epoch=0/micro_step=3630/global_step=3630, RunningAvgSamplesPerSec=8034.5827444872575, CurrSamplesPerSec=8226.1417013974, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:10,114] [INFO] [logging.py:96:log_dist] [Rank 0] step=3640, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:10,115] [INFO] [timer.py:260:stop] epoch=0/micro_step=3640/global_step=3640, RunningAvgSamplesPerSec=8035.837190873405, CurrSamplesPerSec=7325.095672106097, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:10,249] [INFO] [logging.py:96:log_dist] [Rank 0] step=3650, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:10,250] [INFO] [timer.py:260:stop] epoch=0/micro_step=3650/global_step=3650, RunningAvgSamplesPerSec=8036.4308456232675, CurrSamplesPerSec=8822.568066784987, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:10,383] [INFO] [logging.py:96:log_dist] [Rank 0] step=3660, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:10,384] [INFO] [timer.py:260:stop] epoch=0/micro_step=3660/global_step=3660, RunningAvgSamplesPerSec=8037.079164325778, CurrSamplesPerSec=8306.837567693023, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:10,517] [INFO] [logging.py:96:log_dist] [Rank 0] step=3670, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:10,518] [INFO] [timer.py:260:stop] epoch=0/micro_step=3670/global_step=3670, RunningAvgSamplesPerSec=8037.753643841778, CurrSamplesPerSec=8131.45086635163, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:10,651] [INFO] [logging.py:96:log_dist] [Rank 0] step=3680, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:10,651] [INFO] [timer.py:260:stop] epoch=0/micro_step=3680/global_step=3680, RunningAvgSamplesPerSec=8038.590676131279, CurrSamplesPerSec=7650.349293205654, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:10,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=3690, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:10,787] [INFO] [timer.py:260:stop] epoch=0/micro_step=3690/global_step=3690, RunningAvgSamplesPerSec=8038.6097670342615, CurrSamplesPerSec=7219.111876075732, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:10,915] [INFO] [logging.py:96:log_dist] [Rank 0] step=3700, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:10,916] [INFO] [timer.py:260:stop] epoch=0/micro_step=3700/global_step=3700, RunningAvgSamplesPerSec=8040.359129846534, CurrSamplesPerSec=8931.177002927869, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:11,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=3710, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:11,053] [INFO] [timer.py:260:stop] epoch=0/micro_step=3710/global_step=3710, RunningAvgSamplesPerSec=8040.7819060774245, CurrSamplesPerSec=6846.096812037746, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.258789  [57664/60000]\n",
      "[2023-11-20 16:04:11,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=3720, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:11,183] [INFO] [timer.py:260:stop] epoch=0/micro_step=3720/global_step=3720, RunningAvgSamplesPerSec=8042.204130399508, CurrSamplesPerSec=8688.075088196265, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:11,313] [INFO] [logging.py:96:log_dist] [Rank 0] step=3730, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:11,314] [INFO] [timer.py:260:stop] epoch=0/micro_step=3730/global_step=3730, RunningAvgSamplesPerSec=8043.667261229622, CurrSamplesPerSec=7916.581809602454, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:11,445] [INFO] [logging.py:96:log_dist] [Rank 0] step=3740, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:11,446] [INFO] [timer.py:260:stop] epoch=0/micro_step=3740/global_step=3740, RunningAvgSamplesPerSec=8044.720929922304, CurrSamplesPerSec=7971.5939894280455, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:11,582] [INFO] [logging.py:96:log_dist] [Rank 0] step=3750, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:11,583] [INFO] [timer.py:260:stop] epoch=0/micro_step=3750/global_step=3750, RunningAvgSamplesPerSec=8044.637501739906, CurrSamplesPerSec=8297.850262751159, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.283495 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.362305  [   64/60000]\n",
      "[2023-11-20 16:04:12,659] [INFO] [logging.py:96:log_dist] [Rank 0] step=3760, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:12,660] [INFO] [timer.py:260:stop] epoch=0/micro_step=3760/global_step=3760, RunningAvgSamplesPerSec=8045.164647055661, CurrSamplesPerSec=8038.193022907621, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:12,801] [INFO] [logging.py:96:log_dist] [Rank 0] step=3770, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:12,802] [INFO] [timer.py:260:stop] epoch=0/micro_step=3770/global_step=3770, RunningAvgSamplesPerSec=8044.2646250993685, CurrSamplesPerSec=7263.25710265707, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:12,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=3780, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:12,940] [INFO] [timer.py:260:stop] epoch=0/micro_step=3780/global_step=3780, RunningAvgSamplesPerSec=8044.417953515496, CurrSamplesPerSec=8017.785424133811, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:13,073] [INFO] [logging.py:96:log_dist] [Rank 0] step=3790, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:13,074] [INFO] [timer.py:260:stop] epoch=0/micro_step=3790/global_step=3790, RunningAvgSamplesPerSec=8044.951849709492, CurrSamplesPerSec=6893.565896250642, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:13,205] [INFO] [logging.py:96:log_dist] [Rank 0] step=3800, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:13,206] [INFO] [timer.py:260:stop] epoch=0/micro_step=3800/global_step=3800, RunningAvgSamplesPerSec=8046.197400883062, CurrSamplesPerSec=7884.724805404611, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:13,348] [INFO] [logging.py:96:log_dist] [Rank 0] step=3810, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:13,349] [INFO] [timer.py:260:stop] epoch=0/micro_step=3810/global_step=3810, RunningAvgSamplesPerSec=8044.447185584011, CurrSamplesPerSec=5382.920028876233, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:13,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=3820, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:13,485] [INFO] [timer.py:260:stop] epoch=0/micro_step=3820/global_step=3820, RunningAvgSamplesPerSec=8044.832644667849, CurrSamplesPerSec=7813.3500989637905, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:13,619] [INFO] [logging.py:96:log_dist] [Rank 0] step=3830, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:13,621] [INFO] [timer.py:260:stop] epoch=0/micro_step=3830/global_step=3830, RunningAvgSamplesPerSec=8045.062877578065, CurrSamplesPerSec=7363.474310794129, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:13,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=3840, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:13,756] [INFO] [timer.py:260:stop] epoch=0/micro_step=3840/global_step=3840, RunningAvgSamplesPerSec=8045.656142078258, CurrSamplesPerSec=7585.065159649618, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:13,895] [INFO] [logging.py:96:log_dist] [Rank 0] step=3850, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:13,896] [INFO] [timer.py:260:stop] epoch=0/micro_step=3850/global_step=3850, RunningAvgSamplesPerSec=8044.748571011834, CurrSamplesPerSec=7755.112266712891, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.343750  [ 6464/60000]\n",
      "[2023-11-20 16:04:14,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=3860, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,030] [INFO] [timer.py:260:stop] epoch=0/micro_step=3860/global_step=3860, RunningAvgSamplesPerSec=8045.388091978098, CurrSamplesPerSec=8336.504844720497, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:14,163] [INFO] [logging.py:96:log_dist] [Rank 0] step=3870, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,164] [INFO] [timer.py:260:stop] epoch=0/micro_step=3870/global_step=3870, RunningAvgSamplesPerSec=8046.390480527771, CurrSamplesPerSec=8229.167872470876, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:14,297] [INFO] [logging.py:96:log_dist] [Rank 0] step=3880, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,297] [INFO] [timer.py:260:stop] epoch=0/micro_step=3880/global_step=3880, RunningAvgSamplesPerSec=8047.400264997107, CurrSamplesPerSec=7887.504951076896, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:14,435] [INFO] [logging.py:96:log_dist] [Rank 0] step=3890, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,436] [INFO] [timer.py:260:stop] epoch=0/micro_step=3890/global_step=3890, RunningAvgSamplesPerSec=8047.093742329909, CurrSamplesPerSec=6933.450149808865, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:14,571] [INFO] [logging.py:96:log_dist] [Rank 0] step=3900, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,572] [INFO] [timer.py:260:stop] epoch=0/micro_step=3900/global_step=3900, RunningAvgSamplesPerSec=8046.850636023031, CurrSamplesPerSec=7639.028343767786, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:14,711] [INFO] [logging.py:96:log_dist] [Rank 0] step=3910, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,712] [INFO] [timer.py:260:stop] epoch=0/micro_step=3910/global_step=3910, RunningAvgSamplesPerSec=8046.285631461786, CurrSamplesPerSec=7280.987740045568, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:14,844] [INFO] [logging.py:96:log_dist] [Rank 0] step=3920, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,845] [INFO] [timer.py:260:stop] epoch=0/micro_step=3920/global_step=3920, RunningAvgSamplesPerSec=8046.990728237699, CurrSamplesPerSec=8148.482409009502, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:14,976] [INFO] [logging.py:96:log_dist] [Rank 0] step=3930, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:14,977] [INFO] [timer.py:260:stop] epoch=0/micro_step=3930/global_step=3930, RunningAvgSamplesPerSec=8048.00986582097, CurrSamplesPerSec=8180.516121167794, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:15,110] [INFO] [logging.py:96:log_dist] [Rank 0] step=3940, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:15,111] [INFO] [timer.py:260:stop] epoch=0/micro_step=3940/global_step=3940, RunningAvgSamplesPerSec=8048.7604954305025, CurrSamplesPerSec=7412.477384436958, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:15,240] [INFO] [logging.py:96:log_dist] [Rank 0] step=3950, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:15,242] [INFO] [timer.py:260:stop] epoch=0/micro_step=3950/global_step=3950, RunningAvgSamplesPerSec=8050.054024163808, CurrSamplesPerSec=7143.610612874897, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.188477  [12864/60000]\n",
      "[2023-11-20 16:04:15,377] [INFO] [logging.py:96:log_dist] [Rank 0] step=3960, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:15,378] [INFO] [timer.py:260:stop] epoch=0/micro_step=3960/global_step=3960, RunningAvgSamplesPerSec=8050.730737700957, CurrSamplesPerSec=6366.007920886001, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:15,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=3970, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:15,509] [INFO] [timer.py:260:stop] epoch=0/micro_step=3970/global_step=3970, RunningAvgSamplesPerSec=8052.091625330048, CurrSamplesPerSec=7548.166802575711, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:15,640] [INFO] [logging.py:96:log_dist] [Rank 0] step=3980, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:15,641] [INFO] [timer.py:260:stop] epoch=0/micro_step=3980/global_step=3980, RunningAvgSamplesPerSec=8052.883856552797, CurrSamplesPerSec=8092.717998191137, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:15,782] [INFO] [logging.py:96:log_dist] [Rank 0] step=3990, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:15,783] [INFO] [timer.py:260:stop] epoch=0/micro_step=3990/global_step=3990, RunningAvgSamplesPerSec=8052.349407531868, CurrSamplesPerSec=6682.319484205023, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:15,921] [INFO] [logging.py:96:log_dist] [Rank 0] step=4000, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:15,921] [INFO] [timer.py:260:stop] epoch=0/micro_step=4000/global_step=4000, RunningAvgSamplesPerSec=8051.881193375718, CurrSamplesPerSec=7048.510030458985, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:16,064] [INFO] [logging.py:96:log_dist] [Rank 0] step=4010, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:16,065] [INFO] [timer.py:260:stop] epoch=0/micro_step=4010/global_step=4010, RunningAvgSamplesPerSec=8051.158279382653, CurrSamplesPerSec=6959.515076093438, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:16,202] [INFO] [logging.py:96:log_dist] [Rank 0] step=4020, skipped=20, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:16,203] [INFO] [timer.py:260:stop] epoch=0/micro_step=4020/global_step=4020, RunningAvgSamplesPerSec=8051.23600133669, CurrSamplesPerSec=8541.555223215706, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:16,214] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2023-11-20 16:04:16,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=4030, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:16,335] [INFO] [timer.py:260:stop] epoch=0/micro_step=4030/global_step=4030, RunningAvgSamplesPerSec=8052.434178759049, CurrSamplesPerSec=7256.7774864156145, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:16,471] [INFO] [logging.py:96:log_dist] [Rank 0] step=4040, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:16,472] [INFO] [timer.py:260:stop] epoch=0/micro_step=4040/global_step=4040, RunningAvgSamplesPerSec=8052.96262907964, CurrSamplesPerSec=7889.823237221879, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:16,607] [INFO] [logging.py:96:log_dist] [Rank 0] step=4050, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:16,608] [INFO] [timer.py:260:stop] epoch=0/micro_step=4050/global_step=4050, RunningAvgSamplesPerSec=8052.919153177747, CurrSamplesPerSec=7991.053107882829, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.291016  [19264/60000]\n",
      "[2023-11-20 16:04:16,738] [INFO] [logging.py:96:log_dist] [Rank 0] step=4060, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:16,739] [INFO] [timer.py:260:stop] epoch=0/micro_step=4060/global_step=4060, RunningAvgSamplesPerSec=8054.145253660554, CurrSamplesPerSec=8431.821083050634, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:16,873] [INFO] [logging.py:96:log_dist] [Rank 0] step=4070, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:16,875] [INFO] [timer.py:260:stop] epoch=0/micro_step=4070/global_step=4070, RunningAvgSamplesPerSec=8054.148673612248, CurrSamplesPerSec=7966.152951301303, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,004] [INFO] [logging.py:96:log_dist] [Rank 0] step=4080, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,005] [INFO] [timer.py:260:stop] epoch=0/micro_step=4080/global_step=4080, RunningAvgSamplesPerSec=8055.109219481488, CurrSamplesPerSec=8799.143016356902, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,143] [INFO] [logging.py:96:log_dist] [Rank 0] step=4090, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,144] [INFO] [timer.py:260:stop] epoch=0/micro_step=4090/global_step=4090, RunningAvgSamplesPerSec=8054.735707573739, CurrSamplesPerSec=7492.9645778087925, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,276] [INFO] [logging.py:96:log_dist] [Rank 0] step=4100, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,277] [INFO] [timer.py:260:stop] epoch=0/micro_step=4100/global_step=4100, RunningAvgSamplesPerSec=8055.216297977609, CurrSamplesPerSec=7076.941182673802, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,409] [INFO] [logging.py:96:log_dist] [Rank 0] step=4110, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,411] [INFO] [timer.py:260:stop] epoch=0/micro_step=4110/global_step=4110, RunningAvgSamplesPerSec=8055.775111141839, CurrSamplesPerSec=7054.993718625982, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=4120, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,545] [INFO] [timer.py:260:stop] epoch=0/micro_step=4120/global_step=4120, RunningAvgSamplesPerSec=8055.828718986053, CurrSamplesPerSec=7310.931067352997, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,681] [INFO] [logging.py:96:log_dist] [Rank 0] step=4130, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,681] [INFO] [timer.py:260:stop] epoch=0/micro_step=4130/global_step=4130, RunningAvgSamplesPerSec=8055.754395639707, CurrSamplesPerSec=6971.806248863725, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,816] [INFO] [logging.py:96:log_dist] [Rank 0] step=4140, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,817] [INFO] [timer.py:260:stop] epoch=0/micro_step=4140/global_step=4140, RunningAvgSamplesPerSec=8055.99948634737, CurrSamplesPerSec=8193.500274708504, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:17,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=4150, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:17,951] [INFO] [timer.py:260:stop] epoch=0/micro_step=4150/global_step=4150, RunningAvgSamplesPerSec=8056.268649343559, CurrSamplesPerSec=7852.893426557061, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.167969  [25664/60000]\n",
      "[2023-11-20 16:04:18,082] [INFO] [logging.py:96:log_dist] [Rank 0] step=4160, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,083] [INFO] [timer.py:260:stop] epoch=0/micro_step=4160/global_step=4160, RunningAvgSamplesPerSec=8057.119969033761, CurrSamplesPerSec=8481.640999715632, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:18,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=4170, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,211] [INFO] [timer.py:260:stop] epoch=0/micro_step=4170/global_step=4170, RunningAvgSamplesPerSec=8058.594780052072, CurrSamplesPerSec=7504.48577019849, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:18,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=4180, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,344] [INFO] [timer.py:260:stop] epoch=0/micro_step=4180/global_step=4180, RunningAvgSamplesPerSec=8059.625407242458, CurrSamplesPerSec=7557.730052367813, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:18,470] [INFO] [logging.py:96:log_dist] [Rank 0] step=4190, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,471] [INFO] [timer.py:260:stop] epoch=0/micro_step=4190/global_step=4190, RunningAvgSamplesPerSec=8061.404519594596, CurrSamplesPerSec=8467.99545741325, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:18,605] [INFO] [logging.py:96:log_dist] [Rank 0] step=4200, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,606] [INFO] [timer.py:260:stop] epoch=0/micro_step=4200/global_step=4200, RunningAvgSamplesPerSec=8061.52265223378, CurrSamplesPerSec=7938.119706647741, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:18,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=4210, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,737] [INFO] [timer.py:260:stop] epoch=0/micro_step=4210/global_step=4210, RunningAvgSamplesPerSec=8062.251178502564, CurrSamplesPerSec=8545.634025213294, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:18,865] [INFO] [logging.py:96:log_dist] [Rank 0] step=4220, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,866] [INFO] [timer.py:260:stop] epoch=0/micro_step=4220/global_step=4220, RunningAvgSamplesPerSec=8063.682908048159, CurrSamplesPerSec=7905.856629557637, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:18,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=4230, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:18,997] [INFO] [timer.py:260:stop] epoch=0/micro_step=4230/global_step=4230, RunningAvgSamplesPerSec=8064.760673068734, CurrSamplesPerSec=7804.49065271115, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:19,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=4240, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:19,128] [INFO] [timer.py:260:stop] epoch=0/micro_step=4240/global_step=4240, RunningAvgSamplesPerSec=8065.86995193558, CurrSamplesPerSec=7746.160789519247, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:19,263] [INFO] [logging.py:96:log_dist] [Rank 0] step=4250, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:19,264] [INFO] [timer.py:260:stop] epoch=0/micro_step=4250/global_step=4250, RunningAvgSamplesPerSec=8065.964438206973, CurrSamplesPerSec=7615.8383975941215, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.189453  [32064/60000]\n",
      "[2023-11-20 16:04:19,395] [INFO] [logging.py:96:log_dist] [Rank 0] step=4260, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:19,396] [INFO] [timer.py:260:stop] epoch=0/micro_step=4260/global_step=4260, RunningAvgSamplesPerSec=8067.061908030745, CurrSamplesPerSec=7651.003448767279, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:19,530] [INFO] [logging.py:96:log_dist] [Rank 0] step=4270, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:19,531] [INFO] [timer.py:260:stop] epoch=0/micro_step=4270/global_step=4270, RunningAvgSamplesPerSec=8067.524074223058, CurrSamplesPerSec=7503.4369252271135, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:19,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=4280, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:19,662] [INFO] [timer.py:260:stop] epoch=0/micro_step=4280/global_step=4280, RunningAvgSamplesPerSec=8068.6400594955, CurrSamplesPerSec=8852.244294947895, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:19,797] [INFO] [logging.py:96:log_dist] [Rank 0] step=4290, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:19,798] [INFO] [timer.py:260:stop] epoch=0/micro_step=4290/global_step=4290, RunningAvgSamplesPerSec=8069.057877483869, CurrSamplesPerSec=7771.052195813913, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:19,930] [INFO] [logging.py:96:log_dist] [Rank 0] step=4300, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:19,931] [INFO] [timer.py:260:stop] epoch=0/micro_step=4300/global_step=4300, RunningAvgSamplesPerSec=8069.574370871163, CurrSamplesPerSec=7925.6977176769315, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:20,069] [INFO] [logging.py:96:log_dist] [Rank 0] step=4310, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:20,070] [INFO] [timer.py:260:stop] epoch=0/micro_step=4310/global_step=4310, RunningAvgSamplesPerSec=8069.203660703737, CurrSamplesPerSec=7421.28932017362, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:20,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=4320, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:20,207] [INFO] [timer.py:260:stop] epoch=0/micro_step=4320/global_step=4320, RunningAvgSamplesPerSec=8069.167068926137, CurrSamplesPerSec=6862.1978628764255, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:20,344] [INFO] [logging.py:96:log_dist] [Rank 0] step=4330, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:20,345] [INFO] [timer.py:260:stop] epoch=0/micro_step=4330/global_step=4330, RunningAvgSamplesPerSec=8068.551421051209, CurrSamplesPerSec=6655.149522746994, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:20,481] [INFO] [logging.py:96:log_dist] [Rank 0] step=4340, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:20,482] [INFO] [timer.py:260:stop] epoch=0/micro_step=4340/global_step=4340, RunningAvgSamplesPerSec=8068.698317493628, CurrSamplesPerSec=8100.043934821967, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:20,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=4350, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:20,618] [INFO] [timer.py:260:stop] epoch=0/micro_step=4350/global_step=4350, RunningAvgSamplesPerSec=8069.037999809853, CurrSamplesPerSec=8289.394311830281, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.215820  [38464/60000]\n",
      "[2023-11-20 16:04:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] step=4360, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:20,752] [INFO] [timer.py:260:stop] epoch=0/micro_step=4360/global_step=4360, RunningAvgSamplesPerSec=8069.4824659944625, CurrSamplesPerSec=7614.110225499929, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:20,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=4370, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:20,885] [INFO] [timer.py:260:stop] epoch=0/micro_step=4370/global_step=4370, RunningAvgSamplesPerSec=8069.67873838757, CurrSamplesPerSec=7386.166689596346, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=4380, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,017] [INFO] [timer.py:260:stop] epoch=0/micro_step=4380/global_step=4380, RunningAvgSamplesPerSec=8070.14610369977, CurrSamplesPerSec=7743.256007153777, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=4390, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,152] [INFO] [timer.py:260:stop] epoch=0/micro_step=4390/global_step=4390, RunningAvgSamplesPerSec=8070.207131995451, CurrSamplesPerSec=7889.823237221879, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,282] [INFO] [logging.py:96:log_dist] [Rank 0] step=4400, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,283] [INFO] [timer.py:260:stop] epoch=0/micro_step=4400/global_step=4400, RunningAvgSamplesPerSec=8071.148558329019, CurrSamplesPerSec=7921.721536917901, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,413] [INFO] [logging.py:96:log_dist] [Rank 0] step=4410, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,414] [INFO] [timer.py:260:stop] epoch=0/micro_step=4410/global_step=4410, RunningAvgSamplesPerSec=8071.877839202482, CurrSamplesPerSec=7488.15710778844, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=4420, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,548] [INFO] [timer.py:260:stop] epoch=0/micro_step=4420/global_step=4420, RunningAvgSamplesPerSec=8072.183335050506, CurrSamplesPerSec=6777.988486011514, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,682] [INFO] [logging.py:96:log_dist] [Rank 0] step=4430, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,683] [INFO] [timer.py:260:stop] epoch=0/micro_step=4430/global_step=4430, RunningAvgSamplesPerSec=8072.385722777295, CurrSamplesPerSec=6972.71172528443, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=4440, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,816] [INFO] [timer.py:260:stop] epoch=0/micro_step=4440/global_step=4440, RunningAvgSamplesPerSec=8072.993933798249, CurrSamplesPerSec=8051.694891868382, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:21,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=4450, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:21,950] [INFO] [timer.py:260:stop] epoch=0/micro_step=4450/global_step=4450, RunningAvgSamplesPerSec=8073.3142128999625, CurrSamplesPerSec=8166.082258457045, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.151367  [44864/60000]\n",
      "[2023-11-20 16:04:22,084] [INFO] [logging.py:96:log_dist] [Rank 0] step=4460, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:22,085] [INFO] [timer.py:260:stop] epoch=0/micro_step=4460/global_step=4460, RunningAvgSamplesPerSec=8073.377569276784, CurrSamplesPerSec=8149.471932967, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:22,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=4470, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:22,221] [INFO] [timer.py:260:stop] epoch=0/micro_step=4470/global_step=4470, RunningAvgSamplesPerSec=8073.385319614028, CurrSamplesPerSec=7590.427145482822, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:22,353] [INFO] [logging.py:96:log_dist] [Rank 0] step=4480, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:22,354] [INFO] [timer.py:260:stop] epoch=0/micro_step=4480/global_step=4480, RunningAvgSamplesPerSec=8073.876359092432, CurrSamplesPerSec=7042.407744575911, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:22,489] [INFO] [logging.py:96:log_dist] [Rank 0] step=4490, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:22,491] [INFO] [timer.py:260:stop] epoch=0/micro_step=4490/global_step=4490, RunningAvgSamplesPerSec=8073.89324517506, CurrSamplesPerSec=6957.711204997278, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:22,623] [INFO] [logging.py:96:log_dist] [Rank 0] step=4500, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:22,624] [INFO] [timer.py:260:stop] epoch=0/micro_step=4500/global_step=4500, RunningAvgSamplesPerSec=8074.252579516085, CurrSamplesPerSec=7904.459835100118, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:22,759] [INFO] [logging.py:96:log_dist] [Rank 0] step=4510, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:22,760] [INFO] [timer.py:260:stop] epoch=0/micro_step=4510/global_step=4510, RunningAvgSamplesPerSec=8074.319092165964, CurrSamplesPerSec=8591.309201472235, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:22,899] [INFO] [logging.py:96:log_dist] [Rank 0] step=4520, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:22,900] [INFO] [timer.py:260:stop] epoch=0/micro_step=4520/global_step=4520, RunningAvgSamplesPerSec=8073.914483736775, CurrSamplesPerSec=7103.910233678249, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:23,031] [INFO] [logging.py:96:log_dist] [Rank 0] step=4530, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,032] [INFO] [timer.py:260:stop] epoch=0/micro_step=4530/global_step=4530, RunningAvgSamplesPerSec=8074.689349394449, CurrSamplesPerSec=7256.581314878893, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:23,164] [INFO] [logging.py:96:log_dist] [Rank 0] step=4540, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,165] [INFO] [timer.py:260:stop] epoch=0/micro_step=4540/global_step=4540, RunningAvgSamplesPerSec=8075.14045204078, CurrSamplesPerSec=7932.021038945689, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:23,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=4550, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,299] [INFO] [timer.py:260:stop] epoch=0/micro_step=4550/global_step=4550, RunningAvgSamplesPerSec=8075.678242561442, CurrSamplesPerSec=7156.752052895382, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.188477  [51264/60000]\n",
      "[2023-11-20 16:04:23,433] [INFO] [logging.py:96:log_dist] [Rank 0] step=4560, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,434] [INFO] [timer.py:260:stop] epoch=0/micro_step=4560/global_step=4560, RunningAvgSamplesPerSec=8075.986813989704, CurrSamplesPerSec=7512.887097677022, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:23,569] [INFO] [logging.py:96:log_dist] [Rank 0] step=4570, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,570] [INFO] [timer.py:260:stop] epoch=0/micro_step=4570/global_step=4570, RunningAvgSamplesPerSec=8075.935496610991, CurrSamplesPerSec=8033.622314000119, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:23,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=4580, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,702] [INFO] [timer.py:260:stop] epoch=0/micro_step=4580/global_step=4580, RunningAvgSamplesPerSec=8076.38723842539, CurrSamplesPerSec=8181.014750700963, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:23,834] [INFO] [logging.py:96:log_dist] [Rank 0] step=4590, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,835] [INFO] [timer.py:260:stop] epoch=0/micro_step=4590/global_step=4590, RunningAvgSamplesPerSec=8076.636844476855, CurrSamplesPerSec=8158.140530026744, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:23,967] [INFO] [logging.py:96:log_dist] [Rank 0] step=4600, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:23,968] [INFO] [timer.py:260:stop] epoch=0/micro_step=4600/global_step=4600, RunningAvgSamplesPerSec=8077.668331522523, CurrSamplesPerSec=8022.338124981322, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:24,098] [INFO] [logging.py:96:log_dist] [Rank 0] step=4610, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:24,099] [INFO] [timer.py:260:stop] epoch=0/micro_step=4610/global_step=4610, RunningAvgSamplesPerSec=8078.587123979729, CurrSamplesPerSec=7275.659466052311, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:24,233] [INFO] [logging.py:96:log_dist] [Rank 0] step=4620, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:24,234] [INFO] [timer.py:260:stop] epoch=0/micro_step=4620/global_step=4620, RunningAvgSamplesPerSec=8079.043350184489, CurrSamplesPerSec=7502.807758958019, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:24,362] [INFO] [logging.py:96:log_dist] [Rank 0] step=4630, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:24,363] [INFO] [timer.py:260:stop] epoch=0/micro_step=4630/global_step=4630, RunningAvgSamplesPerSec=8080.130195640439, CurrSamplesPerSec=7915.181223093708, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:24,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=4640, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:24,494] [INFO] [timer.py:260:stop] epoch=0/micro_step=4640/global_step=4640, RunningAvgSamplesPerSec=8080.995804034725, CurrSamplesPerSec=8752.378741441147, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:24,625] [INFO] [logging.py:96:log_dist] [Rank 0] step=4650, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:24,626] [INFO] [timer.py:260:stop] epoch=0/micro_step=4650/global_step=4650, RunningAvgSamplesPerSec=8081.877712752846, CurrSamplesPerSec=8043.491924609714, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "loss: 1.106445  [57664/60000]\n",
      "[2023-11-20 16:04:24,760] [INFO] [logging.py:96:log_dist] [Rank 0] step=4660, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:24,761] [INFO] [timer.py:260:stop] epoch=0/micro_step=4660/global_step=4660, RunningAvgSamplesPerSec=8082.186759006615, CurrSamplesPerSec=7457.3690410045565, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:24,893] [INFO] [logging.py:96:log_dist] [Rank 0] step=4670, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:24,894] [INFO] [timer.py:260:stop] epoch=0/micro_step=4670/global_step=4670, RunningAvgSamplesPerSec=8082.623955155271, CurrSamplesPerSec=7338.713324949423, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:25,027] [INFO] [logging.py:96:log_dist] [Rank 0] step=4680, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:25,028] [INFO] [timer.py:260:stop] epoch=0/micro_step=4680/global_step=4680, RunningAvgSamplesPerSec=8082.866199461339, CurrSamplesPerSec=7831.586416151243, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "[2023-11-20 16:04:25,157] [INFO] [logging.py:96:log_dist] [Rank 0] step=4690, skipped=21, lr=[0.001], mom=[0]\n",
      "[2023-11-20 16:04:25,158] [INFO] [timer.py:260:stop] epoch=0/micro_step=4690/global_step=4690, RunningAvgSamplesPerSec=8083.344287730823, CurrSamplesPerSec=7362.464509051015, MemAllocated=0.03GB, MaxMemAllocated=0.96GB\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.128853 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# DeepSpeed Configuration\n",
    "ds_config = {\n",
    "    \"train_micro_batch_size_per_gpu\": 64,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"SGD\",\n",
    "        \"params\": {\n",
    "            \"lr\": 0.001\n",
    "        }\n",
    "    },\n",
    "    \"fp16\": {\n",
    "        \"enabled\": True\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2     \n",
    "    },\n",
    "    \"zero_allow_untested_optimizer\": True,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"wall_clock_breakdown\": False\n",
    "}\n",
    "\n",
    "model_engine, _, _, _ = deepspeed.initialize(args=None,\n",
    "                                                      model=model,\n",
    "                                                      model_parameters=model.parameters(),\n",
    "                                                      config_params=ds_config)\n",
    "\n",
    "def train(dataloader, model_engine, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model_engine.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Ensure data is on the correct device\n",
    "        X, y = X.to(model_engine.local_rank).half(), y.to(model_engine.local_rank)\n",
    "\n",
    "        # Forward pass using model_engine\n",
    "        pred = model_engine(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation and weight update\n",
    "        model_engine.backward(loss)\n",
    "        model_engine.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Ensure data is on the correct device\n",
    "            X, y = X.to(model_engine.local_rank).half(), y.to(model_engine.local_rank)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# Training and Testing Model\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model_engine, loss_fn)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Sneaker\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
